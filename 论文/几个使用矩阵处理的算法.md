### Global alignment of multiple protein interaction networks with application to functional orthology detection.

> Singh, Rohit, Jinbo Xu and Bonnie Berger. “Global alignment of multiple protein interaction networks with application to functional orthology detection.” *Proceedings of the National Academy of Sciences of the United States of America* 105 35 (2008): 12763-8.
>
> 2019-01-09 第二次整理



#### 1. 主要思想

本文的主要思想是利用pagerank的思想（当前节点的重要性由邻居进行决定），每对匹配的相似度性由邻居的相似性决定（利用了邻居这种传递性使得每对的相似度传递依赖于很多的点）从而考虑的是网络的全局信息。此外将其他类型的相似度加入到上面得到的结构相似度中，综合考虑两种相似性（但是这个地方好像 有列和需要为1的约束，因为这样才能和之前的矩阵对应上）。算法的名字称为IsoRank。

**主要流程**

1. 求解得到当前相似度向量
2. 基于相似度向量进行对齐，这里考虑多个网络



#### 2. 数学基础（妙啊）

1. 行和或者列和为1的随机矩阵的特征值为1，证明如下：

$$
A*\begin{vmatrix}1 \\ . \\ . \\ . \\ 1 \end{vmatrix}
= 
1*\begin{vmatrix}1 \\ . \\ . \\ . \\ 1 \end{vmatrix}
$$

在行和为1的条件下，上面的这个式子显而易见。

基于这个理论对于式 $1*\mathbf{a}=A\mathbf{a}$，如果希望求解a那么就等价于求解A矩阵的主特征向量

1. 主特征向量的求解方法: power method
   $$
   R(k+1) \leftarrow AR(k)/|AR(k)|
   $$
   其中$R(k)​$代表第k次迭代的结果

#### 3.  相似度向量求解主要的过程

**第一步**：使用全局结构信息的算法建模

![](https://s2.ax1x.com/2019/01/10/FOlcSf.png)

- 其中R是一个向量，是由相似度矩阵按列展开后形成（展开的方向需要和A配对）



- 式子1的思想特别简单，每个匹配对的结构相似度信息由其邻居结构相似度决定，式子2 就是有权图情况下的表示，如果权重全部置为1就是式子1 的形式，即式子1是式子2的一种特殊形式。
- 式子3是式子1 的向量化表示
- A为一个克罗内克积维数的矩阵（mn*mn）

具体的例子如下图所示：

![](https://s2.ax1x.com/2019/01/10/FOlROg.png)

**第二步：** 融合结构信息和其他相似度信息

其中为了能够和A进行配对，需要对计算得到的相似度进行归一化处理。

![](https://s2.ax1x.com/2019/01/10/FO1tNn.png)

**第三步：**求解相似度向量R

等价于求解最大特征值1对应的特征向量，本文采用幂方法（Power method）进行求解
$$
R(k+1) \leftarrow AR(k)/|AR(k)|
$$
其中$R(k)$代表第k次迭代的结果

#### 3. 基于相似度向量的网络对齐（考虑多个网络的传递性）

**第1步：** 首先构建K部图，其中的每个K为网络的个数

**第2步：** 首先选出相似度最大的节点配对,相似度记为$S_m$

**第3步：** 选出相似度大于$\beta_1*S_m$

**第4步：** 利用前两步中得到节点作为中介，选出$R_{vw}\ge\beta_2R_{uv}$



#### 4. 启示或者说想法

1. 利用这个方法得到的全局结构相似度替换REGAL方法中的相似度，然后利用REGAL的嵌入方法
2. 考虑这个方法的低维表示方法（之前好像已经有算法处理这个问题）
3. 可以考虑使用克罗内克尔积的形式得到上面的A，并且需要保证A为行和或者列和为1的矩阵。

***

### Message-Passing Algorithms for Sparse Network Alignment.

> Bayati, Mohsen, David F. Gleich, Amin Saberi and Ying Wang. “Message-Passing Algorithms for Sparse Network Alignment.” *TKDD* 7 (2013): 3:1-3:31.
>
> 2019-01-10 第二次整理，第二次依然还是没有看完，问题太过于复杂，公式太多



#### 1. 主要思想

这篇论文主要是将网络对齐问题进行泛化的数学定义，只有介绍了几种之前用过的优化方法，之后又提出两种基于置信传播的算法。这篇文章对于网络对齐问题的定义讲得特别的详细，问题具有很强的数学依据，在目标函数中考虑：节点的相似度和两个网络边重叠情况，提出目标函数后研究问题的约束条件。对目标函数就行变形处理或者对约束条件进行松弛处理可以得到不同的处理方法。

#### 2. 数学基础

**二次规划**

一个有n个变数与m个限制的二次规划问题可以用以下的形式描述。首先给定：

- 一个*n* 维的向量 **c**
- 一个*n* × *n* 维的对称矩阵Q
- 一个*m* × *n* 维的矩阵A
- 一个*m* 维的向量 **b**

则此二次规划问题的目标即是在限制条件为
$$
Ax\le b
$$
的条件下，找一个n 维的向量 $x$ ，使得
$$
f(x)=(1/2)x^TQx + c^Tx
$$
为最小。其中$x^T$是的$x$的转置。，注意发现式子中前面有个1/2

根据不同的参数特性，可以得到对问题不同的结论

- 如果Q是半正定矩阵，那么f(x)是一个[凸函数](https://zh.wikipedia.org/wiki/%E5%87%B8%E5%87%BD%E6%95%B0)。
- 如果Q是正定矩阵，那么全局最小值就是唯一的。
- 如果Q=0，二次规划问题就变成线性规划问题。
- 如果有至少一个向量x满足约束而且f(x)在可行域有下界，二次规划问题就有一个全局最小值x。

根据优化理论，一个点x成为全局最小值的必要条件是满足[Karush-Kuhn-Tucker条件](https://zh.wikipedia.org/wiki/Karush-Kuhn-Tucker%E6%A2%9D%E4%BB%B6)（KKT）。当f(x)是凸函数时，KKT条件也是充分条件。

当二次规划问题只有等式约束时，二次规划可以用线性方程求解。否则的话，常用的二次规划解法有：[内点法](https://zh.wikipedia.org/w/index.php?title=%E5%86%85%E7%82%B9%E6%B3%95&action=edit&redlink=1)(interior point)、active set和共轭梯度法等。凸集二次规划问题是[凸优化](https://zh.wikipedia.org/wiki/%E5%87%B8%E5%84%AA%E5%8C%96)问题的一个特例。

#### 3. 网络对齐问题的数学定义（二次整数规划形式）

**整体的思想**：利用克罗内克尔积得到候选的匹配对及每对匹配与其他匹配对之间是否存在互为邻居关系，通过一个指示向量从中选择匹配对使两个图之间的边的匹配度最大，之前可以得到的相似度可以转化到式子、在满足每个节点只能匹配到一个节点的限制条件下利用算法优化求解x使得两个网络的匹配度和相似度都最大。
$$
maximize\quad \alpha w^Tx + \beta/2x^TSx
$$

$$
subject \ to \quad Cx\le 1_{n+m}
$$

**参数的含义**

- $x$ 是指示当前匹配对是否成立的向量，同时也是最后的需要求解的向量

- $S$ 其实就是两个连接矩阵的克罗内克尔积，只是可能不是完整的，矩阵中值代表两个两对匹配节点的节点在各自的网络中是否是邻居，数学定义如下：
  $$
  S[ii',jj'] = \left\{ \begin{array}  
  0 1 \quad if\ (i, j)\in E_A \ and \ (i', j')\in E_B \\
  0 \quad otherwise
  \end{array} \right.
  $$

- $\quad Cx\le 1_{n+m}$ 等价于下面的式子,其实就是唯一匹配限制

  ![](https://s2.ax1x.com/2019/01/10/FOxZlT.png)

- 两个网络的重叠度（经过实际的测试，这个式子是成立的）
  $$
  (1/2)x^TSx = \sum_{ii' \ \ne\ jj'} x_{ii'}x_{jj'}
  $$

**解释：**

- 首先这个就是上面数学基础中形式，式子一模一样，所以接下来的主要问题是理解这个式子的具体含义
- $\alpha w^Tx$ 代表通过某种规则计算出来的相似度， $\beta/2x^TSx$ 代表两个网络的匹配程度（所谓的匹配程度代表两个匹配上的点对之间边的匹配程度，如下图例子中所示，如果$2\leftrightarrow2' \quad 4\leftrightarrow4'$ 两两匹配上，那么重叠的边就是$2\leftrightarrow4和 2'\leftrightarrow4'$）
- 限制条件中，C为一个$节点数 \times 候选匹配数（其实就是二部匹配图中边数）$，具体看下面例子就懂。这个限制的条件代表每个节点只能有一种匹配，即实现一对一的限制

**例子：**

![](https://s2.ax1x.com/2019/01/10/FOxa0H.png)

#### 4. 网络对齐的应用

模式识别、实体识别、生物网络中的共同路径等等

#### 5. 之前的算法

**5.1 IsoRank Algorithm**

主要的思想是在解决问题时直接绕过了约束条件限制，直接利用了行和为1的随机矩阵的性质进行求解主特征向量即可。具体见对应的论文，那个也很清晰。

原始的迭代公式：![](https://s2.ax1x.com/2019/01/10/FOzg8x.png)

克罗内克尔积：![](https://s2.ax1x.com/2019/01/10/FOzzZQ.png)

克罗克内尔积具有的性质1：![](https://s2.ax1x.com/2019/01/10/FXSCin.png)

向量化操作：![](https://s2.ax1x.com/2019/01/10/FXSAMT.png)

经过变形后的迭代公式：![](https://s2.ax1x.com/2019/01/10/FXSmdJ.png)
克罗克内尔积具有的性质2：$Q\bigotimes P = diag[S1_{|E_l|}](B\bigotimes A)$
**理解：**

这其实是一个不断转化的过程（但是感觉没有必要，看原来的论文就很好了）。

针对每次迭代的$z$ 采用bipartite max-weight matching进行匹配得到匹配的结果，从中选出最好的一次作为结果输出。论文的最后选取的是page rank方法（其实也不能说是pagerank方法，就是这种思想）。

**5.2 Linear Program Formulations**

怎么说呢，这其实就是一种优化算法，对于这个层面提不出有用的算法来对其进行优化，所有能用就行。（或者说将问题转化为这种形式后，利用这种形式优化）

这种想法来源于：mixed integer translations或者quadratic assignment。 在这个方法中引入另外的一个变量y，将之前的目标函数变换为另外的一种形式。观察下面的式子其实就是将匹配部分使用另外的一种形式进行表达，其中能够能够将目标表达式进行化简。

![](https://s2.ax1x.com/2019/01/11/FXauWQ.png)

写成矩阵形式后：![](https://s2.ax1x.com/2019/01/11/FXdB9g.png)

**5.3 Klau's Iterative Matching Relaxation**

在这种方式中引入了Lagrange multipliers，将5.2中的的对称限制转移到目标函数中，

![](https://s2.ax1x.com/2019/01/11/FXwGPU.png)

将上面的目标函数展开后可以得到下面的式子，以及结合分析可以将式子进行一步化简。

![](https://s2.ax1x.com/2019/01/11/FX0Zo6.png)

对w进行重新的改写后，可以将目标表达式进行化简。

![](https://s2.ax1x.com/2019/01/11/FX00yj.png)

另外论文中还讲了一个tightened LPs。具体的过程就省略了，如果需要就看原文。

#### 6. 本文提出的算法：

借鉴信息传播（置信传播）算法求解目标函数。在提出一个基本方法后又提出一个新的改进算法，但是这两个方法都没有看懂，手动尴尬脸。

#### 7. 启示或者想法

首先网络对齐问题的数学定义形式是一个比较好的理论基础，可以利用其他的信息往这个方面上靠。然后就可以得到一个问题的求解方法。但难点也在于对于问题及已知信息的建模过程。

其次，这篇论文其实是克罗克内尔积的一个使用。邻接矩阵的克罗克内尔积需要配合一个匹配指示函数或者说矩阵，此外现在克罗克内积使用的结构上的信息，可以尝试将将其他的信息整合到这个矩阵中。或者说使用这个连接信息传递得到更多的信息。

***

### Multimodal Network Alignment.

> Nassar, Huda and David F. Gleich. “Multimodal Network Alignment.” *SDM* (2017).
>
> 2019-01-20 第二次整理
>
> 本文主要针对的是生物网络
>
> spring 上的文章，根据这类文章总结出来，spring期刊上面的论文不要看了，太长也太难

#### 中心思想

根据IsoRank方法带来的启示，利用网络的多模式构建多模式（不同类型的边）的邻接矩阵，然后在这个邻接矩阵上利用PageRank以及矩阵分解的方法对其进行求解得到最终的结果。

#### 本文具体的方法

**IsoRank**

目标矩阵，其中$Y$中代表的就是不同网络中两个节点的相似度
$$
Y = \alpha PYQ^T + (1-\alpha)S
$$
其中S为初始的相似度矩阵，用户可以没有这个相似度矩阵，如果没有则默认填入$|V_A|^{-1}|V_B|^-{1}$

当S中没有具体的相似度信息时，$rank(S)=1$，而对于秩为1的矩阵，具有$S=uv^T$,在使用PageRank算法后，经过t次迭代的结果为：
$$
Y^{(t)} = (1-\alpha) \sum_{k=0}^{t-1} \alpha^kP^kuv^T(Q^T)^k + \alpha^tP^tuv^T(Q^T)^k
$$
注意上面的式子的计算效率一般比较好，一般t位于5~25之间，$\alpha=0.9$

**Our decomposition**

多模式下的S矩阵：

![](https://s2.ax1x.com/2019/01/20/kPAk1x.png)

其中，$\gamma=m^{-1}|V_A|^{-1}|V_B|^{-1}$, S是一个秩为m的矩阵

如果使用M和N分别表示，多模式下的邻接矩阵，那么目标矩阵变为：
$$
Y_{MN} = \alpha P_MY_{MN}Q_{MN}Q_N^T + (a-\alpha)S
$$
依然继续利用PageRank进行迭代优化可以得到如图所示的具体算法：

![](https://s2.ax1x.com/2019/01/20/kPACN9.png)

定理：如果$Y=UV^T$ 是一个秩为k的矩阵Y的分解，如果$X_i$是拥有一阶秩的矩阵$u_iv_i^T$的最大权重匹配，并且$f_i=X_i\bullet(u_iv_i^T)$是上述匹配的权重，如果$f^*$是$f_i $中最大的值，那么$f^* $ 是$Y$ 的一个$1/k$的近似。

冲突的解决：

由于是多模式，在不同的模式下相同的点可能会匹配到不同的点，对于这种冲突具有两种处理方法：

方法1：采用贪婪匹配算法

方法2：将其建模成为二部图网络，在这个图中寻找最大的二部匹配图

#### 启示或者想法

多模式信息的使用不太常见，可以考虑使用，但是涉及到具体的数据集。

其次对于PageRank算法的使用好像需要好好的了解，也许能够再重新利用一次。

最后如果$Y_i=u_iv_i^T$ ,那么Y所代表的的匹配就是两个向量$u_i和v_i$分别按照从大到小排列后的一一对应。

***

### Low Rank Spectral Network Alignment.

> Nassar, Huda, Nate Veldt, Shahin Mohammadi, Ananth Grama and David F. Gleich. “Low Rank Spectral Network Alignment.” *WWW* (2018).
>
> 2019-01-13 第二次整理



**前言**： 其实和大多数的spectral alignment方法一样，都是希望能够从所有点的配对情况（配对的情况一般存在一个矩阵中，并且矩阵中的值代表的是当前匹配对的相似度信息）中找到一个选择机制（向量或者是矩阵）来从中选出最为合适的配对。如何进行选择呢？选择时通过一对一的限制条件可以知道特殊位置是不能同时被选中的。那么这类算法中的研究点在于：

- 如何将其中所用到的矩阵进行降维，即用低阶矩阵来表达原始的目标。
- 其次，两个节点之间的匹配相似度如何得到？可以通过迭代的方式得到，也可以通过基于定义的结构相似度或属性相似度得到，此外除去相似度的计算，还有各种情况的组合，即利用一些当前没有被人们使用过的信息。
- 选择机制（向量或者说维度怎么求解），即优化算法的使用也是一个研究的方向，找到更加高效的方法来进行识别。

**思想：** 分析前人的目标函数，考虑到之前的目标函数中仅考虑到了网络的匹配信息，没有考虑利用不匹配信息，所以文中提出一个模型能够同时考虑边的匹配、不匹配、匹配冲突（这里说的是两对配对点之间的联系的对应情况）。在提出这个模型后，由于其中的匹配矩阵维度很大，于是将矩阵进行分解或者说得到矩阵的低阶表示方式，然后在低阶的矩阵上进行识别。最后在得到的低阶矩阵的表达形式中进行最后的网络对齐工作。

#### 主要流程

1. **匹配与不匹配信息**
   ![](https://s2.ax1x.com/2019/01/13/Fvh9US.png)
   其中对于冲突情况时，代表的是两类冲突，一边右边另外一边没有边。
2. **传统的优化目标**

![](https://s2.ax1x.com/2019/01/13/FvOK3V.png)

其中的M为所有的匹配情况形式成的$mn \times mn$矩阵，矩阵中的值代表的是匹配的相似度。$y$是一个mn维的向量（由一个$m \times n$ 的矩阵压扁形成，其中的每个位置代表两个节点是否匹配），其中的每个值代表当前匹配对是否是成立的。

缺点：是由M的定义所导致的，其中仅包含匹配部分的信息没有包含不匹配、或者匹配冲突等信息。

1. **本文提出的目标**(其实是EigenAlign 算法中提出来，本文的主要目标是寻找其的低阶矩阵表示)

在$P(i_B, i_B^{'}) = 1 \ and \ P(j_B, j_B^{'}) = 1$的条件下(这里的P为y的矩阵形式)：

![](https://s2.ax1x.com/2019/01/13/FvOSht.png)

上面的式子表示的带无匹配以及匹配冲突的渗透图的矩阵表示形式为：

![](https://s2.ax1x.com/2019/01/13/FvOABQ.png)

所以目标函数可以表示为：

![](https://s2.ax1x.com/2019/01/13/FvhnET.png)

利用行和为1的随机矩阵的主特征值为0，可以得到下面的等价优化目标：

![](https://s2.ax1x.com/2019/01/13/FvOwjO.png)

1. **Low Rank Factors of EigenAlign**（需要严格的数学推导，但是具体没有搞太懂）

经过一系列严格的数学公式的推倒可以得到X的四因子形式、三因子形式以及两因子形式，对于具体的推导过程就不在详细地叙述，如果需要就看原文，其中用到的一个重要思想依然还是SVD分解，最后基于提出的分解算法得到最后的算法。

![](https://s2.ax1x.com/2019/01/13/FvXC5R.png)

基于上面的算法我们可以得到两因子形式的一个近似。

1. **基于低阶矩阵的网络对齐**

由于低阶矩阵是采用迭代的算法计算得到，在每次的迭代中能够产生一个u和v向量，由这两个向量能够计算得到$Y$,所以先考虑一个向量u和v的情况下如何进行对齐。想法特别简单，对于$Y$的中放入结果全是正（分）的，那么对齐进行排序，最大（小）的值就是匹配的。如果是两种混在一起的，可以先将两类进行分开，分别计算，再将其结果进行汇总，这种方法是通过证明，是可行的。



#### 想法或者启示  

可以加入其它的相似度。

***

### Multiple Anonymized Social Networks Alignment.

> Zhang, Jiawei and Philip S. Yu. “Multiple Anonymized Social Networks Alignment.” *2015 IEEE International Conference on Data Mining* (2015): 599-608.
>
> 2019-01-22 第一次整理

#### 主要思想或核心

本文整体的思想比较简单，不外乎满足三点限制：最大化边的重叠度，每个节点最多匹配到一个节点，以及在多网络的情况下需要保持传递性。根据上面的三点限制建立优化目标，寻找转移矩阵和匹配矩阵使上面的优化目标符合条件。

#### 主要方法

1. 构建转移矩阵的优化目标

![](https://s2.ax1x.com/2019/01/22/kFJTpt.png)

其中：S为邻接矩阵，T为转移矩阵，其中$(T^{(i, j)})^TS^{(i)}T^{(i, j)}$代表将$S^{(i)}$投射到$S^{(j)}$后的样子，即使得两个网络具有可比性。这个具体的数学基础不知道，但是经过实际的测试后确实是这个结果。后面个的限制条件，即简单的一对一限制。

1. 引入传递性惩罚因子

传递性惩罚因子：想法特别简单，就是从不同路径传播的结果应该是相近的，下面以三个网络的作为例子，

![](https://s2.ax1x.com/2019/01/22/kFN1FH.png)

泛化到多个网络的情况下，其实就是对于所有三个网络组合的结果

![](https://s2.ax1x.com/2019/01/22/kFN4k4.png)

加入了惩罚因子后目标函数变为：

![](https://s2.ax1x.com/2019/01/22/kFUp9A.png)



上面的这个式子中的限制让这个式子特别的难解，于是对上面的结果进行松弛处理

1. 松弛目标限制

就是T中只能进行0或1取值松弛为0到1之间的任意数，于是限制条件变为：

![](https://s2.ax1x.com/2019/01/22/kFUhKP.png)

1. 使用梯度下降算法迭代计算

![](https://s2.ax1x.com/2019/01/22/kFaTL6.png)

1. 传递匹配限制

   对于三个网络时不匹配限制为：

![](https://s2.ax1x.com/2019/01/22/kFdzh4.png)

 拓展到多网络：

![](https://s2.ax1x.com/2019/01/22/kFwdvn.png)

1. 最后的优化目标：

   ![](https://s2.ax1x.com/2019/01/22/kFw5b6.png)

   其中的多网络的传递性不是凸的，将这个限制放到目标函数中。最后这个优化问题可以使用，Scipy.Optimization和GLPK进行求解。

***

## Spectral Alignment of Network(Graphs)

> Feizi, Soheil, Gerald Quon, Mariana Recamonde Mendoza, Muriel Médard, Manolis Kellis and Ali Jadbabaie. “Spectral Alignment of Networks.” *CoRR* abs/1602.04181 (2015): n. pag.
>
> 2019-01-15 第一次整理
>
> 这篇论文有代码地址为：https://github.com/SoheilFeizi/spectral-graph-alignment

#### 主要思想：

这篇论文主要不仅考虑了边的重叠度同时还考虑了边的不重合以及匹配的两对点之间不存在联系，为什么需要考虑边不匹配或者说匹配的两个点之间不存在联系的情况呢？具体见下面的这个例子,如果在不考虑边的没有匹配上的情况时，$X_0$ 显然是需要匹配到$X_1$ 但是其实匹配到$X_2$更为合适。综合考虑边的各种匹配情况后将这些信息相似度矩阵（匹配矩阵或者说渗透图）中，之后将目标建模成为二次分配问题（quadratic assignment problem）进行识别。在得到优化目标后提出两种优化的方法来求解问题：基于主特征向量的方式和低阶的对齐算法。

![](https://s2.ax1x.com/2019/01/15/FzDesS.png)

注：这篇论文中提到的数学概念比较多，已经整理成为专门的一篇文章

> 常用的数学基础

#### 针对QAP（二次分配）的前人算法

- Exact search methods

  主要方法有，分支限界、割平面法。

  缺点是：费时间

- Linearizations

  主要的方式是使用mixed integer program(MILP).

- Semidefinite/convex relaxations（半正定和凸优化）

  Semidefinite programming（SDP）算法。以及计算机视觉领域的方法。

- 其他的方法

  贝叶斯网络、Message passing、以及其他的启发式算法

#### 本文算法

**图同构问题：** 如果存在一个置换矩阵P存在使得$G_1 = PG_2P^T$成立，则称两个网络是同构的。

首先定义两对匹配点之间的关系：

![](https://s2.ax1x.com/2019/01/15/FzfajA.png)

基于上面的定义，现在可以得到边的匹配矩阵A。

此时的求解目标为（其实感觉这个是混合整数规划的的目标）：

![](https://s2.ax1x.com/2019/01/15/FzfoNT.png)

- **EigenAlign Algorithm算法**

1. 第一步求解A矩阵的主特征向量， 在求解主特征向量时（暂时不考虑二部匹配的限制，因为在下一步处理时考虑到了这个问题）
2. 利用特征向量的性质$Ax = \lambda x$ 问题的求解转化为最大权重的二分匹配优化：

![](https://s2.ax1x.com/2019/01/15/Fzh8rn.png)

将上述问题近似化后（将约束进行放缩）：
$$
\mathop{max}\limits_{y}\quad y^TAy, \\
||y||_2 \le 1
$$
对于第一步求解的主特征向量就是上面这个优化目标的的一个近似解。

后面还讲了一些噪声的生成办法。

- **LowRankAlign Algorithm**

前注：里面涉及到一些没有看懂的知识点。仅列出主要的思想：

1. 利用正交矩阵来松弛优化目标
2. 在特征向量方向投影

$$
max\quad Tr(G_1XG_2X^T),\\
X \in \tau.
$$

其中$\tau$ 是一个正交矩阵

**定理3** 当U和和V分别为网络的两个特征向量矩阵时,存在
$$
X_0 = VU^T = \sum_{i=1}^n v_i u_i^t
$$
是上面优化目标的一个解。

其他部分看不懂。。。



### 想法或启示

在线性代数的范围内还大有可为，但是需要线性代数理论知识作为支持。