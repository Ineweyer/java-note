# java多线程并发

![img](https://s2.ax1x.com/2019/03/24/AYfCuT.jpg)

##  1. 多线程基础

### 1.1 Java线程实现/创建的方式

```java
package multithread;

import java.util.concurrent.*;

class Thread1 implements Runnable {
    public void run() {
        // coding here
        System.out.println("Thread 1 name: " + Thread.currentThread().getName());
    }
}

class Thread2 extends Thread {
    public void run() {
        // coding here
        System.out.println("Thread 2 name: " + Thread.currentThread().getName());
    }
}

class Thread3 implements Callable<Integer> {

    @Override
    public Integer call() throws Exception {
        // coding here
        System.out.println("Thread 3 name: " + Thread.currentThread().getName());
        return 1;
    }
}

public class StartThread {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        //way1，实现Runnable接口
        new Thread(new Thread1()).start();
        //way2，基础自Thread类
        new Thread2().start();
        //way3，实现Callable接口+利用线程池
        ExecutorService pool = Executors.newSingleThreadExecutor();
        Future futureTask = pool.submit(new Thread3());
        System.out.println("Result from thread 3: " + futureTask.get());
        //way4，直接使用线程池
        pool.submit(new Runnable() {
            @Override
            public void run() {
                //coding here
                System.out.println("Thread 4 name: " + Thread.currentThread().getName());
            }
        });

        pool.shutdown();
    }
}
```

### 1.2 四种线程池

> - newCachedThreadPool：如果当前没有可用线程则新创建，如果存在可用就重用之前的线程，对于长时间没有使用的线程移出线程池**，可用就重用，不可用就新建，回收长时间不使用**
>
> - newFixedThreadPool：**固定数量的可重用线程池，以共享无界队列方式来运行这些线程**，如果任务失败可以使用另外的线程来代替其执行，线程存在到被显示关闭
>
> - newScheduledThreadPool：**固定线程数量线程池，可以指定延迟后执行或周期执行**
>
>   ```java
>   ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3);
>   scheduledThreadPool.schedule(newRunnable(){
>   	 @Override
>   	 public void run() {
>   		 System.out.println("延迟三秒");
>    	}
>    }, 3, TimeUnit.SECONDS);
>   scheduledThreadPool.scheduleAtFixedRate(newRunnable(){
>    	@Override
>    	public void run() {
>    		System.out.println("延迟 1 秒后每三秒执行一次");
>    	}
>    },1,3,TimeUnit.SECONDS);
>   ```
>
> - newSingleThreadExecutor：只有一个线程的线程池，不同单个线程的是**如果线程死掉，会重新创建一个线程来代替原来的线程继续执行下去，而不使用线程池的方式中线程死了就结束了**

![](https://s2.ax1x.com/2019/03/23/AJ1lZ9.png)

### 1.3 线程生命周期（状态）

![img](https://images2015.cnblogs.com/blog/716271/201703/716271-20170320112245721-1831918220.jpg)

- **新建状态（new）**，对象被创建后进入，调用start之前
- **就绪状态（Runnable）**，可执行状态，现在只缺计算计算资源，也是获取CPU前置状态
- **运行状态（Running）**，获取CPU权限进行执行
- **阻塞状态（Blocked）**，因为某些原因放弃CPU使用权
  - 同步阻塞：线程获取synchronized同步锁失败时进入
  - 等待阻塞：通过调用线程的wait方法进入，需要转化为同步阻塞后才能有机会进入到接续状态
  - 其他阻塞：调用sleep()或join()或发出了I/O请求时进入
- **死亡状态（Dead）**，通过下面的三种方式进入死亡状态：
  - 正常结束
  - 异常结束
  - 调用stop，不推荐使用，同时释放对象持有的所有锁，容易造成状态不稳定，以及死锁

#### 1.3.1 终止线程的4种方式

```java
// 1. 正常运行结束

// 2. 使用退出标志退出线程

// 3. Interrupt 方法结束线程(需要考虑阻塞（会有异常） + 非阻塞（能够查看到当前线程的状态）两种情况)
while (!isInterrupted()){ //非阻塞过程中通过判断中断标志来退出
	 try{
	 	Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出
 	}catch(InterruptedException e){
 		e.printStackTrace();
		break;//捕获到异常之后，执行 break 跳出循环
 	}
}

// 4. thread.stop()进行关闭，不推荐使用，同时释放对象获取的所有锁，容易导致状态不可知
```

#### 1.4 线程基本方法

> - sleep：保持锁，让出一段执行时间，没有优先级概念
> - wait：等待获取当前对象的同步锁（当前已经获得锁，是需要让别人通知自己是否获得锁）
> - yeild：交出CPU权限，重新回到就绪状态进行竞争，只给具有更高优先级的线程让步
> - join：等待该线程执行完，最常用于父子线程中，父线程等待子线程
> - notify：唤醒在此对象监视器上等待的单个线程，选择是任意的，调用器wait() 方法，在对象的监视器上等待，直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程**通知线程等待其他线程放弃**
> - interrupt：是给这个线程一个通知信号，会影响这个线程内部的一个**中断标识位**。这个线程本身并**不会**因此而**改变状态**(如阻塞，终止等)
>   - 调用 interrupt()方法并**不会中断一个正在运行的线程**
>   - **阻塞状态**调用interrupt()方法会**抛出InterruptedException异常**，提前结束阻塞状态
>   - 抛出异常前一般**清除中断标志位**，调用 isInterrupted()方法将会返回 false。
>   - 中断状态是线程固有的一个标识位，可以通过此标识位**安全的终止线程**

其他方法：

> 1. isAlive()： 判断一个线程是否存活。
> 2. activeCount()： 程序中活跃的线程数。
> 3. enumerate()： 枚举程序中的线程。
> 4. currentThread()： 得到当前线程。
> 5. isDaemon()： 一个线程是否为守护线程。
> 6. setDaemon()： 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线
>   程依赖于主线程结束而结束)
> 7. setName()： 为线程设置一个名称。
> 8. setPriority()： 设置一个线程的优先级。
> 9. getPriority():：获得一个线程的优先级。

#### 1.4.1 sleep与wait

1. 所属类不同
2. 是否依然是监控状态保持者？
3. 锁是否释放？
4. 阻塞类型不同，wait需要notify进行通知

#### 1.4.2 start与run的区别

> 1. start方法用来启动线程，启动子线程后当前线程就可以**继续往下执行**
> 2. 调用start方法子线程进入**就绪状态**，等待获取cpu权限
> 3. run是一个方法体，线程**进入运行状态，开始运行run函数当前的代码**

#### 1.4.3 yield 的问题

> - Yield是一个静态的原生(native)方法
> - Yield告诉当前正在执行的线程把运行机会交给线程池中拥有相同优先级的线程。
> - Yield不能保证使得当前正在运行的线程迅速转换到可运行的状态**可能有延迟**
> - 它仅能使一个线程**从运行状态转到可运行状态，而不是等待或阻塞状态**

### 1.5 Java 后台线程

#### 1.5.1 基本概念

**定义：**守护线程--也称“服务线程”，他是后台线程，它有一个特性，即为用户线程 提供公共服务，在没有用户线程可服务时会自动离开。

**在调用start方法之前通过setDaemon(true)来设置，优先级较低，并且在守护线程中产生的线程也是守护线程，线程时JVM级别，只要jvm没有停止且还有其他的服务对象，线程依旧是活跃的。即说明其生命周期和系统相同**

#### 1.5.2 Daemon线程会导致finally不能执行？

>  当不存在非Daemon线程时，Daemon线程会退出，**在构建Daemon线程时，不能依靠finally块中的内容来确保执行关闭或者清理资源的逻辑。**

#### 1.5.3 一个简单的java程序中包含多个线程

```java
/**
 * Created by Genge on 2016-06-07.
 */
public class MultiThread {
    public static void main(String[] args) {
        ThreadInfo[] threadInfos = ManagementFactory.getThreadMXBean().dumpAllThreads(false, false);
        for (ThreadInfo threadInfo : threadInfos){
            System.out.println("[" + threadInfo.getThreadId() + "]" + threadInfo.getThreadName());
        }

    }
}

// 运行结果如下：
[10]Monitor Ctrl-Break
[5]Attach Listener       //添加事件
[4]Signal Dispatcher    // 分发处理给JVM信号的线程
[3]Finalizer           //调用对象finalize方法的线程
[2]Reference Handler   //清楚reference线程
[1]main   //main线程,程序入口
```

#### 1.5.4 线程优先级Priority参数靠谱吗？

> 不靠谱，**线程优先级不能作为程序正确性的依赖！**

### 1.6 LockSupport

LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。 
LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程，而且park()和unpark()**不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”**问题。
因为park() 和 unpark()有许可的存在；调用 park() 的线程和另一个试图将其 unpark() 的线程之间的竞争将保持活性。

```java
// 返回提供给最近一次尚未解除阻塞的 park 方法调用的 blocker 对象，如果该调用不受阻塞，则返回 null。
static Object getBlocker(Thread t)
// 为了线程调度，禁用当前线程，除非许可可用。
static void park()
// 为了线程调度，在许可可用之前禁用当前线程。
static void park(Object blocker)
// 为了线程调度禁用当前线程，最多等待指定的等待时间，除非许可可用。
static void parkNanos(long nanos)
// 为了线程调度，在许可可用前禁用当前线程，并最多等待指定的等待时间。
static void parkNanos(Object blocker, long nanos)
// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。
static void parkUntil(long deadline)
// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。
static void parkUntil(Object blocker, long deadline)
// 如果给定线程的许可尚不可用，则使其可用。
static void unpark(Thread thread)
```

### 1.7 线程上下文切换

**任务的状态保存及再加载, 这段过程就叫做上下文切换**

![img](https://s2.ax1x.com/2019/03/24/AYPzQ0.png)

#### 1.7.1 基本概念

- 进程：是指一个程序运行的实例
- 上下文：是指某一时间点**CPU 寄存器**和**程序计数器的内容**。
- 寄存器： CPU 内部的数量较少但是速度很快的内存，寄存器通过对常用值（通常是运算的中间值）的快速访问提高运行速度
- 程序计数器，是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，两个作用
  - 指示单前运行或者下一条运行
  - 线程切换时保存接着执行的位置

#### 1.7.2 PCB-“切换桢”

上下文切换过程中的信息是保存在**进程控制块（PCB, process control block），**信息会一直保存直到下次使用。

#### 1.7.3 上下文切换的活动

> 1. 挂起一个进程，将这个进程在 CPU 中的状态（上下文）存储于内存中的某处。
> 2. 在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复。
> 3. 跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程在程序中。

#### 1.7.4 引起上下文切换的原因

> 1. 当前执行任务的时间片用完之后，系统 CPU 正常调度下一个任务；
> 2. 当前执行任务碰到 IO 阻塞，调度器将此任务挂起，继续下一任务；
> 3. 多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务；
> 4. 用户代码挂起当前任务，让出 CPU 时间；
> 5. 硬件中断；

### 1.8 volatile关键字

> - **变量可见性availablePermits()；**其一是保证该变量对所有线程可见，这里的可见性指的是当一个线程修改了变量的值，那么新的值对于其他线程是可以立即获取的。
> - **禁止重排序：**

**比synchronized更轻量的同步锁，**在访问 volatile 变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此 volatile 变量是一种比 sychronized 关键字更轻量级的同步机制。

**使用场景：一个变量被多个线程共享，线程直接给这个变量赋值**

> 必须同时满足下面两个条件才能保证在并发环境的线程安全：
>
> - 对变量的写操作不依赖于当前值（比如 i++），或者说是单纯的变量赋值（boolean flag = true）
> - 该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。

### 1.9 如何在两个线程之间共享数据

**通信方式：**共享内存

**关注问题：**可见性、有序性和原子性。JVM内存模型解决了可见性和有序性，程序需要交由程序员进行处理。

**实现方式：**

> 1. 将数据抽象成一个类，并将数据的操作作为这个类的方法，然后将当前的数据放入线程中
> 2. 使用匿名内部类方式，这样就能够直接利用方法中数据

### 1.10 ThreadLocal作用（线程本地存储）

ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，ThreadLocal 的作用是提供线程内的局部变量，**这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度**

> ThreadLocalMap（线程的一个属性，用于存放ThreadLocal）
> 1. 每个线程中都有一个自己的 ThreadLocalMap 类对象，可以将线程自己的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。
> 2. 将一个共用的 ThreadLocal 静态实例作为 key，将不同对象的引用保存到不同线程的ThreadLocalMap 中，然后在线程执行的各处通过这个静态 ThreadLocal 实例的 get()方取得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。
> 3. ThreadLocalMap 其实就是线程里面的一个属性，它在 Thread 类中定义ThreadLocal.ThreadLocalMap threadLocals = null;

**使用场景：**解决数据库连接、Session管理（就是将当前的连接信息放到线程本地存储中，在线程的任意位置就能够访问这个连接）。

### 1.11 java中用到的线程调度

#### 1.11.1 两种线程调度方式

> - **抢占式调度：**抢占式调度指的是每条线程执行的时间、线程的切换都由**系统控制**。多个线程交替执行，一个线程的堵塞不会导致整个进程阻塞
> - **协同式调度：**某一线程执行完后**主动通知系统**切换到另一线程上执行。多个线程串行执行，缺点是一个线程有问题，导致整个系统崩溃。

#### 1.11.2 JVM线程调度实现（抢占式调度）

> 按照线程优先级分配CPU时间片，优先级越高越优先执行，但同时**保证线程不会饥饿**（并非非高优先级所有时间片，低优先级没有时间片）

#### 1.11.3 线程让出CPU情况

> 1. 线程正常结束
> 2. 主动放弃，如yield
> 3. 进入阻塞，被动放弃（等待阻塞+同步阻塞+其他阻塞）

### 1.12 进程调度算法



> - 优先调度算法
>
>   - 先来先服务调度算法（FCFS），
>     - 原理：从当前的等待调度队列中取队首进程让其执行
>     - 特点：算法简单，实现基本上的公平
>   - 短作业(进程)优先调度算法（SJF/SPF），
>     - 原理：从就绪队列中选出一个估计运行时间最短的作业（进程），将CPU分配给它一直运行到其让出CPU，再次重新调度。
>     - 特点：没有照顾紧迫性作业。
>
> - 高优先权调度算法
>
>      为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。
>
>   - 非抢占式优先权算法，
>
>     - 原理：分配后等待其执行完成后再次进行调度。
>     - 特点：主要用于批处理系统、或者实时性不高的实时系统
>
>   - 抢占式优先权调度算法
>
>     - 原理：先将处理机分配给优先权最高的进程，在其执行期间，只要又出现了一个优先权更高的进程，进程调度程度就立即停止当前进程，将处理机分配给新的优先权更高的进程。
>     - 特点：适用于严格的实时系统，以及对性能要求较高的批处理和分时系统
>
>   - 高响应比优先调度算法
>
>     - 原理：为了解决短作业优先法中长作业的运行得不到保证，引入动态优先权，作业的优先级随着等待时间的增加而以速度a提高，保证长作业等待一段时间后，必然有机会分配到处理机，计算公式为：$R_p = \frac{等待时间+要求服务时间}{要求服务时间}=\frac{响应时间}{要求服务时间}$
>
>     - 特点：短作业+FCFS+长作业三者兼顾，但是计算响应比费时。
>
>       > 1. 作业等待时间相同，要求服务时间越短，其优先权越高，有利于短作业
>       > 2. 要求服务时间相同，等待时间越长，其优先级越高，实现先来先服务
>       > 3. 对于长作业，作业的优先级随着等待时间的增加而提高，不会使长作业长期得不到服务
>
> - 基于时间片的轮转调度算法
>
>   - 时间片轮转法
>
>     - 原理：将cpu的运行时间分片，每次允许一个线程执行一个时间片，当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程。
>     - 特点：就绪队列中所有的进程在给定的时间内均能获得一个时间片的处理时间
>
>   - 多级反馈队列调度算法
>
>     - 原理：
>
>       > 1. 设置多个就绪队列，队列的优先级递减，但是队列的时间片长度递增（一般是2倍关系）
>       > 2. 新进程进入第一个队列，队内FCFS，每经过一次时间片后移入下一个队列
>       > 3. 当且仅当前面的队列为空，才能调度当前队列中的进程
>
>     - 特点：如果第一个队列的时间片长度略大于多数人的人机交互处理时，能够满足各种类型用户的需要。



## 2. 集合工具类（Collections）
### 2.1 CopyOnWriteArrayList
和ReetrantReadWriteLock读写锁的思想非常类似，也是存在写则互斥，或者否则共享。读取完全不用加锁，写入也不会阻塞读取操作。

**原理：**类中所有的可变操作都是通过创建底层数组的新副本来实现。写入操作在添加集合的时候加了锁，保证了同步，避免了多线程写的时候回copy出多个副本来

四、java之同步集合和并发集合

### 2.2 **同步集合类**

- HashTable
- Vector
- 同步集合包装类，Collections.synchronizedMap()和Colletions.synchronizedList()

#### 2.2.1 实现原理

就是最简单的每次操作之前锁住整个表。

### 2.3 **并发集合类**

- ConcurrentHashmap
- CopyOnWriteArrayList，存在问题，数据一致性以及内存占用问题
- CopyOnWriteHashSet

#### 2.3.1 实现原理

- ConcurrentHashMap：把整个Map 划分成几个片段，只对相关的几个片段上锁，同时允许多线程访问其他未上锁的片段。**之前是分段上锁，后面变成了针对里面的节点进行，大大地加快了并发的程度**
- CopyOnWriteArrayList：允许多个线程以**非同步的方式读**，当有线程写的时候它会将整个List复制一个副本给它。如果在**读多写少（适用场景）**这种对并发集合有利的条件下使用并发集合，这会比使用同步集合更具有可伸缩性。**原理特别简单就是在存在写时就往副本里写，写完以后更新引用**

#### 2.3.2 使用建议

一般在不需要使用多线程的情况下，只用到HashMap、ArrayList，只要真正用到多线程的时候就一定要考虑使用同步，使用同步集合或者并发集合。

### 2.4 同步集合和并发集合的性能对比

同步集合比并发集合会慢得多，主要原因是锁，同步集合会对整个May或List加锁

### 2.5 ConcurrentHashMap并发

**理论基础**：减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。

**段：**将内部细分了若干个小的 HashMap，称之为段(Segment)，默认分为16段。

**分段锁：**需要操作时，不是对真个HashMap加锁，而是首先判断在哪个段中，然后对其加锁。

**ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成**

每个 Segment 守护一个 HashEntry 数组里的元素,当对 HashEntry 数组的数据进行修改时，必须首先获得它对应的 Segment 锁。

![img](https://images2015.cnblogs.com/blog/764863/201606/764863-20160620202714522-1795796503.png)

#### 2.5.1 java1.8改进

> 改进一：**取消segments字段**，直接采用transient volatile HashEntry<K,V>[] table保存数据，采用table数组元素作为锁，从而实现了对**每一行数据进行加锁**，进一步减少并发冲突的概率。
>
> 改进二(HashMap的改进)：将原先table数组＋单向链表的数据结构，变更为**table数组＋单向链表＋红黑树的结构**。对于hash表来说，最核心的能力在于将key hash之后能均匀的分布在数组中。如果hash之后散列的很均匀，那么table数组中的每个队列长度主要为0或者1。但实际情况并非总是如此理想，虽然ConcurrentHashMap类默认的加载因子为0.75，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为O(n)；因此，对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能。

## 3. 原子类（Atomic）

![img](https://camo.githubusercontent.com/8d43784c43dcc9f46d3cc917066fb945fa877857/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f31302f33302f313636633538623738353336383233343f773d3132303026683d36353726663d706e6726733d3439363135)

### 3.1 基本原子类
基本原子类主要有：

- AtomicInteger：整形原子类
- AtomicLong：长整型原子类
- AtomicBoolean ：布尔型原子类

每个类中的方法基本都是相同，类似于下面的样子：

```java
public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并自增
public final int getAndDecrement() //获取当前的值，并自减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
```

**优点**是能够在多环境使用原子类保证线程安全

**基本原子类实现原理：**主要利用CAS（compare and swap） + volatile 和 native方法来保证原子操作，从而避免synchronized的高开销，提高执行效率。

### 3.2 数组类型原子类

使用原子的方式更新数组里的某个元素

- AtomicIntegerArray：整形数组原子类
- AtomicLongArray：长整形数组原子类
- AtomicReferenceArray ：引用类型数组原子类

其中基本的方法基本相同，类似于如下所示：

```java
public final int get(int i) //获取 index=i 位置元素的值
public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValue
public final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增
public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减
public final int getAndAdd(int delta) //获取 index=i 位置元素的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update）
public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
```

### 3.3 引用类型原子类

基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用 引用类型原子类。

- AtomicReference：引用类型原子类
- AtomicStampedRerence：原子更新引用类型里的字段原子类
- AtomicMarkableReference ：原子更新带有标记位的引用类型

上面三个类提供的方法几乎相同，主要的功能是**为引用类型提供原子操作管理**。

```java
AtomicReference<Person> ar = new AtomicReference<Person>(); //是一个引用管理，保证引用类型处理时的原子性
```

### 3.4 对象属性修改类型原子类

如果需要原子更新某个类里的某个字段时，需要用到对象的属性修改类型原子类。

- AtomicIntegerFieldUpdater:原子更新整形字段的更新器
- AtomicLongFieldUpdater：原子更新长整形字段的更新器
- AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

要想原子地更新对象的属性需要两步。第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法 newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新的对象属性必须使用 public volatile 修饰符。

```java
AtomicIntegerFieldUpdater<User> a = AtomicIntegerFieldUpdater.newUpdater(User.class, "age"); //直接对象的中的作用域进行原子操作
a.getAndIncrement(user)；
```

## 4. executor

## 5. tools

具体见AQS部分

##  6. AQS(AbstractQueuedSynchronizer)

![AQS](https://camo.githubusercontent.com/75950bb0b6b7ba5672236abf0c7c096a822b1d39/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31302d33312f36313131353836352e6a7067)

### 6.1 简单介绍

AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。

###  6.2 AQS原理

**AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**

CLH队列是一个虚拟的双向队列。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个节点（Node）来实现锁的分配。

AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。

AQS定义两种资源共享方式：Exclusive(独占，如ReentrantLock)和Share(共享，如Semaphore、CountDownLatch、CyclicBarrier、ReadWriteLock)

使用了模板方法模式，自定义同步器需要重写下面几个AQS提供的模板方法

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

#### 6.2.1 **Semaphore经常用于限制获取某种资源线程数量。**

支持公平模式和非公平模式，通过调用acquire方法得到申请许可，通过调用release释放许可，释放之前需要先获得许可。可以申请多个许可，也可以释放多个许可。

> availablePermits()可以查看当前可用的许可数目
>
> acquire和tryAcquire：前置阻塞知道获取许可，后者尝试获取许可，成功，返回true失败返回false

#### 6.2.2 **CountDownLatch（倒计时器）**

它允许一个或多个线程等待，直到其他的线程执行完后再执行。

三种典型用法：某一个线程开始运行前等待n个线程执行完毕；实现多个线程开始执行任务的最大并行性；死锁检测。

#### 6.2.3 **CyclicBarrier(循环栅栏)**

和CountDownLatch非常相似，它可以实现线程间的计数等待，但是功能比CountDownLatch更加复杂和强大。适用于多线程计算数据，最后合并计算结果的应用场景。使用实例如下所示

```java
private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5); //其中5代表需要达到的等待线程条件，支持两个参数，后面可以添加一个方法优先于子线程子线程执行

//子线程中操作
cyclicBarrier.await(2000, TimeUnit.MILLISECONDS);
//当有五个线程调用await后才继续执行await后面的方法
```

> - public int await()：挂起当前线程，直至所有的线程都到达barrier状态再同时执行后续任务
> - public int await(long timeout, TimeUnit unit)：让这些线程等待至一定的时间，如果还有线程没有到达 barrier 状态就直接让到达 barrier 的线程执行后续任务

#### 6.2.4 **CyclicBarrier和CountDownLatch的区别**

1. CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用。
2. 对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。
3. CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。

![CyclicBarrieråCountDownLatchçåºå"](https://camo.githubusercontent.com/5c19d9e66ffaf3d7193b01948279db9b9b3b98d3/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f4a6176612532302545372541382538422545352542412538462545352539312539382545352542462538352545352541342538372545462542432539412545352542392542362545352538462539312545372539462541352545382541462538362545372542332542422545372542422539462545362538302542422545372542422539332f4151533333332e706e67)

##  7. 锁

### 7.0 锁类型

从策略角度：

> - **乐观锁：**适用于读多写少的情况，在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作。通过CAS实现，CAS是一种原子操作吗，比较当前值跟传入值是否一样，一样则更新，否则失败。AQS框架下是乐观锁
>
> - **悲观锁：**适合频繁写的情况，悲观锁就是Synchronized

加锁模式：

> - **独占锁：（悲观锁）**独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。
> - **共享锁：（乐观锁）**共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。



###  7.1锁优化

这里的锁优化主要是指 JVM 对 synchronized 的优化。

#### 7.1.1 自旋锁

互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。

自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。

##### 7.1.1.1 适应性自旋锁

在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由**前一次在同一个锁上的自旋次数及锁的拥有者的状态**来决定。（**能够动态地不断优化自旋时间**）

##### 7.1.1.2 优缺点

> **是优点也是缺点，主要看场合**
>
> **优点：**锁竞争不是特别激烈的时候，性能提升明显
>
> **缺点：**锁竞争特别激烈的时候，性能明显下降

##### 7.1.1.3 自旋锁的开启

JDK1.6 中-XX:+UseSpinning 开启；
-XX:PreBlockSpin=10 为自旋次数；
JDK1.7 后，去掉此参数，由 jvm 控制；

#### 7.1.2 锁消除

锁消除是指对于**被检测出不可能存在竞争的共享数据的锁进行消除**。

锁消除主要是通过**逃逸分**来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。
对于一些看起来没有加锁的代码，其实隐式的加了很多锁，例如每个 StringBuilder.append() 方法中都有一个同步块。

##### 7.1.2.1 逃逸分析
逃逸分析的基本行为就是分析对象动态作用域,即对象可以在作用域外访问则说明发生了逃逸。
**方法逃逸:**：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。
**线程逃逸:** 甚至可以被外部线程访问，则称为线程逃逸。

####### 7.1.2.1.1 基于逃逸分析可以实现：
一、同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。

二、将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配。

三、分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。

#### 7.1.3 锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。
如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部

#### 7.1.4 轻量级锁

JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。

以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。

![img](https://cyc2018.github.io/CS-Notes/pics/bb6a49be-00f2-4f27-a0ce-4ed764bc605c.png)

下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。

![img](https://cyc2018.github.io/CS-Notes/pics/051e436c-0e46-4c59-8f67-52d89d656182.png)

轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。

当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。

![img](https://cyc2018.github.io/CS-Notes/pics/baaa681f-7c52-4198-a5ae-303b9386cf47.png)

如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。

#### 7.1.5 偏向锁

偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。**让第一个获取锁对象的线程之后不用再次获取锁**

当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。

当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

![img](https://cyc2018.github.io/CS-Notes/pics/390c913b-5f31-444f-bbdb-2b88b688e7ce.jpg)

### 7.2 Synchronized同步锁

#### 7.2.1 Synchronized作用范围

**Synchronized同步锁是作用在对象上，基于此判断能否锁住以及是否是在请求同一把锁**

> this：非静态方法
>
> .class：静态方法
>
> 对象实例：同步代码块

#### 7.2.2 Synchronized核心组件

> 1) Wait Set：哪些调用 wait 方法被阻塞的线程被放置在这里；
> 2) Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中；
> 3) Entry List：Contention List 中那些有资格成为候选资源的线程被移动到 Entry List 中；
> 4) OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为 OnDeck；
> 5) Owner：当前已经获取到所资源的线程被称为 Owner；
> 6) !Owner：当前释放锁的线程。

#### 7.2.3 Synchronized实现

![Synchronized实现](https://s2.ax1x.com/2019/03/23/AJBoBq.png)

> 1. JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争，JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。
> 2. Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。
> 3. Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。
> 4. OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中，直到某个时刻通过 notify或者 notifyAll 唤醒，会重新进去 EntryList 中。
> 5. 处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。
> 6. **Synchronized 是非公平锁**。 Synchronized 在线程进入 ContentionList 时，**等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList**，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。参考：https://blog.csdn.net/zqz_zqz/article/details/70233767
> 7. 每个对象都有个 monitor 对象，**加锁就是在竞争 monitor 对象**，**代码块加锁**是在前后分别加上**monitorenter 和 monitorexit 指令来实现的**，**方法加锁**是通过一个**标记位**来判断的
> 8. synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。
> 9. **Java1.6**，synchronized 进行了很多的优化，有**适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等**，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。
> 10. 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做**锁膨胀**；
> 11. JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁。

#### 7.2.4 synchronized锁类型

##### 7.2.4.1 重量级锁（Mutex Lock）

Synchronized 是通过对象内部的一个叫做**监视器锁（monitor）**来实现的。监视器锁本质又是依赖于底层的操作系统的**Mutex Lock** 来实现的，而操作系统实现线程切换需要从**用户态转到核心态**，而这个切换是比较**耗时**，称之为重量级锁。

##### 7.2.4.2 锁升级

四种状态**依次升级（单向）**：

- 无锁状态：
- 偏向锁：**只有一个线程执行同步块时进一步提高性能**，因为其只需要在置换ThreadId的时候依赖依次CAS原子指令。**目的是某个线程获得锁以后消除这个线程锁重入CAS的开销**（看起来得到了偏护），但存在多线程竞争的情况就需要撤销偏向锁，变为轻量锁。
- 轻量级锁： **CAS 操作来避免重量级锁使用互斥量的开销**，适应的场景是**线程交替执行同步块**的情况，如果存在同一时间访问同一锁（synchronized都是互斥锁）的情况，就会导致**锁膨胀**为重量级锁，
- 重量级锁：

### 7.3 Lock

![img](https://s2.ax1x.com/2019/03/24/AJjpL9.md.png)

#### 7.3.0 Lock接口中的主要方法

> 1. void lock(): 执行此方法时, 如果锁处于空闲状态, 当前线程将获取到锁. 相反, 如果锁已经被其他线程持有, 将禁用当前线程, 直到当前线程获取到锁.
>
> 2. boolean tryLock()：如果锁可用, 则获取锁, 并立即返回 true, 否则返回 false. 该方法和lock()的区别在于, tryLock()只是"试图"获取锁, 如果锁不可用, 不会导致当前线程被禁用,当前线程仍然继续往下执行代码. 而 lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行.
> 3. void unlock()：执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程
>   并不持有锁, 却执行该方法, 可能导致异常的发生.
> 4. Condition newCondition()：条件对象，获取等待通知组件。该组件和当前的锁绑定，
>   当前线程只有获取了锁，才能调用该组件的 await()方法，而调用后，当前线程将缩放锁。
> 5. getHoldCount() ：查询当前线程保持此锁的次数，也就是执行此线程执行 lock 方法的次
>   数。
> 6. getQueueLength（）：返回正等待获取此锁的线程估计数，比如启动 10 个线程，1 个
>   线程获得锁，此时返回的是 9
> 7. getWaitQueueLength：（Condition condition）返回等待与此锁相关的给定条件的线程估计数。比如 10 个线程，用同一个 condition 对象，并且此时这 10 个线程都执行了condition 对象的 await 方法，那么此时执行此方法返回 10
> 8. hasWaiters(Condition condition)：查询是否有线程等待与此锁有关的给定条件(condition)，对于指定 contidion 对象，有多少线程执行了 condition.await 方法
> 9. hasQueuedThread(Thread thread)：查询给定线程是否等待获取此锁
> 10. hasQueuedThreads()：是否有线程等待此锁
> 11. isFair()：该锁是否公平锁
> 12. isHeldByCurrentThread()： 当前线程是否保持锁锁定，线程的执行 lock 方法的前后分别是 false 和 true
> 13. isLock()：此锁是否有任意线程占用
> 14. lockInterruptibly（）：如果当前线程未被中断，获取锁
> 15. tryLock（）：尝试获得锁，仅在调用时锁未被线程占用，获得锁
> 16. tryLock(long timeout TimeUnit unit)：如果锁在给定等待时间内没有被另一个线程保持，则获取该锁。

#### 7.3.1 ReentrantLock

可重入锁，与synchronized的区别：**能完成synchronized所能完成的所有工作，此外还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法**

里面包含两个内部类：NonfairSync和FairSync

#### 7.3.2 公平锁与非公平锁

- **非公平锁：**JVM按照随机，就近原则分配锁的机制称为不公平锁。**直接尝试获取锁，获取不到自动到队尾等待**
- **公平锁：**公平锁指的是锁的分配机制是公平的，通常先对锁提出获取请求的线程会先被分配到锁。**加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得**

ReentrantLock提供了是否为公平锁的初始化方式，默认为非公平锁。

两种锁特点：

> 1. **非公平锁性能**比公平锁**高** 5~10 倍，因为公平锁需要在多核的情况下维护一个队列
> 2. Java 中的 synchronized 是非公平锁，ReentrantLock 默认的 lock()方法采用的是非公平锁。

#### 7.3.3 ReentrantLock 与 synchronized

> 1.  ReentrantLock通过方法lock()与unlock进行**手动加锁和解锁**操作，解锁操作必须放置于finally中，而synchronized自动加锁和解锁。
> 2.  ReentrantLock 相比 synchronized 的优势是**可中断、公平锁、多个锁（通过lock对象的newCondition创建）**。

公共点：

> 1. 都是用来协调多线程对共享对象、变量的访问
> 2. 都是可重入锁，同一线程可以多次获得同一个锁
> 3. 都保证了可见性和互斥性

不同点：

> 1. ReentrantLock **显示**的获得、释放锁，synchronized **隐式**获得释放锁
> 2. ReentrantLock **可响应中断、可轮回**，synchronized 是**不可以响应中断的**，为处理锁的不可用性提供了更高的灵活性
> 3. ReentrantLock 是**API 级别**的，synchronized 是 **JVM 级别**的
> 4. ReentrantLock **可以实现公平锁**
> 5. ReentrantLock 通过 Condition 可以**绑定多个条件**
> 6. 底层实现不一样， synchronized 是**同步阻塞**，使用的是**悲观**并发策略，lock 是**同步非阻塞**，采用的是**乐观**并发策略
> 7. Lock 是一个**接口**，而 synchronized 是 Java 中的**关键字**，synchronized 是内置的语言实现。
> 8. synchronized 在发生**异常时**，会**自动释放**线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在**finally 块中释放锁**。
> 9. Lock 可以让等待锁的线程**响应中断**，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，**不能够响应中断。**
> 10. 通过 Lock 可以**知道有没有成功获取锁**，而 synchronized 却**无法办到**。
> 11. 能实现**锁分离**，Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。

#### 7.3.4 Condition 类和 Object 类锁方法区别

> 1. Condition 类的 awiat 方法和 Object 类的 wait 方法等效
> 2. Condition 类的 signal 方法和 Object 类的 notify 方法等效
> 3. Condition 类的 signalAll 方法和 Object 类的 notifyAll 方法等效
> 4. ReentrantLock 类**可以唤醒指定条件的线程，而 object 的唤醒是随机的**

#### 7.3.4 tryLock 和 lock 和 lockInterruptibly 的区别

> 1. tryLock 能获得锁就返回 true，不能就立即返回 false，tryLock(long timeout,TimeUnit
>    unit)，可以增加时间限制，如果超过该时间段还没获得锁，返回 false
>
> 2. lock 能获得锁就返回 true，不能的话一直等待获得锁
> 3. lock 和 lockInterruptibly，如果两个线程分别执行这两个方法，但此时**中断这两个线程，lock 不会抛出异常，而 lockInterruptibly 会抛出异常。**

#### 7.3.5 AtomicInteger与ReentrantLock

> **在多线程程序中，诸如++i 或 i++等运算不具有原子性，是不安全的线程操作之一**
>
> 使其线程安全的方式：
>
> - 使用synchronized同步操作，
> - 使用Lock
> - 使用AtomicInteger，性能优于前两种方法，是最合适的选择

### 7.4 Semaphore 信息号

Semaphore 是一种**基于计数的信号量**。可以设定阈值，多个线程竞争许可信号，做完后释放，申请数量操作阈值后，申请线程就会被阻塞。

**作用：**构建对象池、资源池等，比如数据库连接池。

#### 7.4.1 demo

```java
Semaphore semp = new Semaphore(5);
try { // 申请许可
	semp.acquire();
	try {
		// 业务逻辑
	} catch (Exception e) {
	} finally {
		// 释放许可
		semp.release();
	}
} catch (InterruptedException e) {
}
```

#### 7.4.2 实现互斥锁（计数器为1）

创建计数为 1 的 Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。

#### 7.4.3 Semaphore 与 ReentrantLock

>  **Semaphore 基本能完成 ReentrantLock 的所有工作**
>
> 1. 都需要手工进行加锁（acquire，等价于lockInterruptibly）和释放锁（release）
> 2. 也实现了可轮询的锁请求与定时锁的功能

### 7.5 ReadWriteLock

![img](https://s2.ax1x.com/2019/03/24/AJOlnA.png)

为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制

- 读锁：很多人同时读
- 写锁：只能有一个人在写，且不能同时读取，

```java
// 需要使用两把锁（读锁和写锁），但是两把锁并非是独立的
ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
readWriteLock.readLock().lock();
new Thread(new Runnable() {
    @Override
    public void run() {
        readWriteLock.writeLock().lock();
        System.out.println("In thread");
        readWriteLock.writeLock().unlock();
    }
}).start();
System.out.println("In main");
Thread.sleep(2000);
readWriteLock.readLock().unlock();
```

### 7.6 分段锁

分段锁也并非一种实际的锁，而是一种思想 ConcurrentHashMap 是学习分段锁的最好实践

### 7.7 锁优化方式

> - **减少锁持有时间**，避免不必要的加锁
> - **减少锁粒度**，将大对象拆分为小对象，分段锁（例如Concurrent）
> - **锁分离**，最常见的为读写锁分离
> - **锁粗化**，如果频繁加锁的开销大于针对某个大对象（代码块）的加锁，则用针对这整块只加一次锁
> - **锁清除**，编译器根据逃逸分析，清除不必要的加锁

### 7.8 同步锁和死锁

#### 7.8.1 基本概念

- 同步锁：为了保证线程同步互斥，就是指并发执行的多个线程，在同一时间内只允许一个线程访问共享数据。可以通过synchronized关键字获取对象的同步锁。
- 死锁：多个线程都互相等待资源造成阻塞，其中没有一个能够执行。
  - 死锁四条件：互斥 + 请求与保持 + 不可剥夺 + 循环等待

#### 7.8.2 线程池原理

**特点：**线程复用；控制最大并发数；管理线程

##### 7.8.2.1 线程复用

**实现原理：**我们可以继承重写Thread 类，在其 start 方法中添加不断循环调用传递过来的 Runnable 对象。循环方法中不断获取 Runnable 是用 Queue 实现的。

##### 7.8.2.2 线程池的组成

一般组成：

> 1. 线程池管理器：用于创建并管理线程池
> 2. 工作线程：线程池中的线程
> 3. 任务接口：每个任务必须实现的接口，用于工作线程调度其运行
> 4. 任务队列：用于存放待处理的任务，提供一种缓冲机制

![img](https://s2.ax1x.com/2019/03/24/AYkwGj.png)

ThreadPoolExecutor构造方法如下：

```java
public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue) {
	this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,Executors.defaultThreadFactory(), defaultHandler);
}
```

> 1. corePoolSize：指定了线程池中的线程数量。
> 2. maximumPoolSize：指定了线程池中的最大线程数量。
> 3. keepAliveTime：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间，即多次时间内会被销毁。
> 4. unit：keepAliveTime 的单位。
> 5. workQueue：任务队列，被提交但尚未被执行的任务。
> 6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
> 7. handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。

##### 7.8.2.3 拒绝策略

**拒绝条件：**线程池中线程用完，等待队列已经排满。

**JDK内置拒绝策略**

- AbortPolicy ： 直接抛出异常，阻止系统正常运行。
- CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
- DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
- DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢分失，这是最好的一种方案。

##### 7.8.2.4 线程池工作原理

![img](https://s2.ax1x.com/2019/03/24/AYMkkt.md.png)

注意：上面的判断条件应该为阻塞线程未满。

> 1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。
> 2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：**判断是否可以创建或者只能放到队列中**
>   a) 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；
>   b) 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；
>   c) 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；
>   d) 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常 RejectExecutionException。
> 3. 当一个线程完成任务时，它会从队列中取下一个任务来执行。**队列中调度**
> 4. 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后,它最终会收缩到 corePoolSize 的大小。**回收长时间不用**

#### 7.8.3 Java阻塞队列原理

- 队列空：阻塞消费者，唤醒生产者
- 队列满：阻塞生产者，唤醒消费者

##### 7.8.3.1 **主要方法：**

![img](https://s2.ax1x.com/2019/03/24/AYQ3bd.md.png)

> - 抛出异常：抛出一个异常；
> - 特殊值：返回一个特殊值（null 或 false,视情况而定）
> - 则塞：在成功操作之前，一直阻塞线程
> - 超时：放弃前只在最大的时间内阻塞

**插入方法：**

> - add（如果立即可行且不会违反容量控制），将指定元素插入，成功是返回true，空间不足抛IllegalStateException，如果元素为空，抛出NullPointerException
> - offer，与add类似，但是不抛出异常，错误是返回false，并且可以设定等待的时间
> - put，空间够同add和offer，否则阻塞等待可用空间

**获取数据方法：**

> - poll，立即取队首对象，取不到返回空，可以设置等待的时间
> - take，阻塞等待获取对首对象
> - drainTo，一次性从BlockingQueue获取所有可用的数据对象，可以提升获取数据效率，不需要多次分批加锁或释放锁

##### 7.8.3.2 java中的阻塞队列

所有的都实现了BlockingQueue，而BlockingQueue继承自Collection

> 1. ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。
>
>    > 使用**数组**实现的有界阻塞队列，按照**先进先出**的原则对元素进行排序，默认情况下不保证访问者公平的访问队列（但可以实现公平）
>
> 2. LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。
>
>    > 基于**链表**的阻塞队列，按照**先进先出（FIFO）**的原则对元素进行排序，由于其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，高效处理并发数据（生产者和消费者可以并发）。默认是无限大小。
>
> 3. PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。
>
>    > 支持优先级，无界队列，默认升序排序，可以自定义compareTo方法（或者传入Comparator）指定排序规则，同级不保证顺序
>
> 4. DelayQueue：使用优先级队列实现的无界阻塞队列。
>
>    > 支持延时获取元素的无界阻塞队列，队列元素必须实现Delayed接口，创建元素时能够指定多久才能从队列中获取当前的元素。适用场景有：
>    >
>    > - 缓存系统的设计，一个线程循环查询，能够访问说明过期
>    > - 定时任务调度，适用DelayQueue保存当前将会执行的任务和时间，一旦获取到任务就开始执行，TimerQueue就是使用DelayQueue实现。
>
> 5. SynchronousQueue：不存储元素的阻塞队列。
>
>    > 是一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素，数据由生产者线程直接向消费者传送，吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue
>
> 6. LinkedTransferQueue：由链表结构组成的无界阻塞队列。
>
>    > 由 链 表 结 构 组 成 的 无 界 阻 塞 TransferQueue 队 列 ,相比其他阻塞队列，多了tryTransfer和transfer
>    >
>    > - transfer方法（**强卖，必须被消费才返回**）：有生产者在等待接受元素，transfer方法直接将数据传给消费者，否则添加到队列的tail节点，并**等待该元素被消费者消费才返回**
>    > - tryTransfer 方法，和transfer不同的时，如果不存在消费者的话返回false。
>
> 7. LinkedBlockingDeque：由链表结构组成的双向阻塞队列
>
>    > 链表结构组成的**双向阻塞队列**，可以从队列的两端插入和移出元素。e 多了 addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast 等方法。First表示从从第一个元素开始操作，Last表示从最后一个元素开始操作。可以设置容量放置过度膨胀，使用在“工作窃取”模式中。

### 7.9 CAS（比较并交换-乐观锁机制-锁自旋）

#### 7.9.1 概念及特性

**算法过程：**cas返回的是当前V的真实值

> - 包含三个参数CAS(V,E,N)，V为要更新的变量值（内存值），E为预期值（旧），N为新值
> - 如果V=E，将V的值设为N
> - 否则，已经有其他的线程做了更新，当前线程什么也不做

**使用CAS操作一个变量时，仅有一个线程操作成功，其余都被告知失败，但允许再次尝试**，通过这种原理，即使没有锁也可以发现其他线程对当前线程的干扰，并进行适当的处理。

**CAS是乐观锁的一种实现**，其原理是CPU的切换时间比CPU指令集操作时间更长

#### 7.9.2 原子包java.util.concurrent.atomic(自旋锁)

特点：这些类的实例包含的方法具有排他性，**即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由 JVM 从等待队列中选择一个另一个线程进入**

AtomicInteger方法里面一个方法的分析：

```java
//里面使用自旋保证这一步操作不能丢，就是不论结果如何这个方法的功能是要在当前值的基础上加1，只要保证这个加1操作能够正常完成就行了。
public final int getAndIncrement() { 
	for (;;) { //CAS 自旋，一直尝试，直达成功
 		int current = get();
	 	int next = current + 1;
 		if (compareAndSet(current, next))
 			return current;
 	}
}
//cas的实现由UnSafe提供，这个提供直接对内存操作的类。
 public final boolean compareAndSet(int expect, int update) {
	 return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
 } 
```
#### 7.9.3 Unsafe 

Unsafe类使Java拥有了像C语言的指针一样**操作内存空间的能力**，同时也带来了指针的问题。Unsafe采用代理模式实现，对于普通的调用会抛出一个Security异常。只能有主类加载器加载的类才能调用这个方法。提供其他的方法获取时会抛出SecurityException异常。

一种通过反射的获取方式：

```java
Field f = Unsafe.class.getDeclaredField("theUnsafe");
f.setAccessible(true);
Unsafe unsafe = (Unsafe) f.get(null);
```

**作用：**

> - **内存管理****。**包括分配内存、释放内存等
> - **非常规的对象实例化**,allocateInstance()方法提供了另一种创建实例的途径。
> - **操作类、对象、变量。**包含staticFieldOffset（静态域偏移）、defineClass（定义类）、defineAnonymousClass（定义匿名类）、ensureClassInitialized（确保类初始化）、objectFieldOffset（对象域偏移）等方法
> - **数组操作。**包括了arrayBaseOffset（获取数组第一个元素的偏移地址）、arrayIndexScale（获取数组中元素的增量地址）等方法。arrayBaseOffset与arrayIndexScale配合起来使用，就可以定位数组中每个元素在内存中的位置。
> - **多线程同步。**包括锁机制、CAS操作等。包括compareAndSwapInt、compareAndSwap等方法（其他不推荐使用），Unsafe类的CAS操作可能是用的最多的，**AtomicInteger等类都是通过该方法来实现的。**
> - **挂起与恢复。**包括了park、unpark等方法。
> - **内存屏障。**loadFence、storeFence、fullFence等方法，java8中引入的，避免代码重排序。

#### 7.9.4 ABA问题

CAS 算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。**取出之前值，下时刻比较，这不能保证在这两个时刻之间没有其他线程发生ABA修改**

**ABA问题：**修改值，然后又改回来。

> 一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A

**ABA解决：**通过一个只增不减的版本号进行解决，之后修改的版本号小于当前版本号才能修改，否则拒绝。

### 7.10 什么是AQS（抽闲队列同步器）

AQS 定义了一套多线程访问共享资源的同步器框架，很多同步类都依赖于它，比如常用的ReentrantLock/Semaphore/CountDownLatch

![CLH队列](https://s2.ax1x.com/2019/03/24/AYgU7d.png)

CLH队列：

> volatile int state（代表共享资源）和一个 FIFO 线程等待队列（多线程争用时进入此队列）
>
> state的三种访问方式：
>
> - getState()
> - setState()
> - compareAndSetState()

AQS定义两种资源共享方式

> - **Exclusive** 独占资源，
>   - 特点：独占，只能一个线程能执行，
>   - 例子：ReentrantLock
> - **Share** 共享资源
>   - 特点：共享，多个线程可同时执行
>   - 例子：-Semaphore/CountDownLatch

**AQS 只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现**，如果自定义同步器，在实现时只需要实现共享资源state的获取和释放即可。队列维护已经交由顶层封装好。

自定义主要实现的方法有：

> 1．isHeldExclusively()：该线程是否正在独占资源。只有用到 condition 才需要去实现它。
> 2．tryAcquire(int)：独占方式。尝试获取资源，成功则返回 true，失败则返回 false。
> 3．tryRelease(int)：独占方式。尝试释放资源，成功则返回 true，失败则返回 false。
> 4．tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0 表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
> 5．tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回 false。

#### 7.10.1 同步器的实现是ABS核心（state资源状态计数）

关于state：

> - state可以根据不同的用途初始化为不同的值，如ReentrantLock中初始化为0，CountDownLatch初始为指定值。
> - state变为零，当前是未锁定状态，需要unpark其他的等待线程
> - 每次进入（加锁），state加1
> - 每次退出（放锁），state减1

ReentrantLock实现

> - state 初始化为 0，表示未锁定状态。
>
> - A 线程lock()时，会调用 tryAcquire()独占该锁并将 state+1。此后，其他线程再 tryAcquire()时就会失败，直到 A 线程 unlock()到 state=0（即释放锁）为止.
>
> - A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但获取多少次就需要释放多少次，保证state 为零。

CountDownLatch实现

> - 任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）
> - 每个子线程执行完后 countDown()一次，state会 CAS 减 1。
> - 等到所有子线程都执行完后(即 state=0)，会 unpark()主调用线程

#### 7.10.2 ReentrantReadWriteLock 实现独占和共享两种方式

> 自定义同步器要么是独占方法，要么是共享方式，他们也只需实现 tryAcquiretryRelease、tryAcquireShared-tryReleaseShared 中的一种即可。但 AQS 也**支持自定义同步器同时实现独占和共享两种方式，如 ReentrantReadWriteLock**。

## 8. 关于多线线程的一些理解

### 8.1 各个Thread之间的关系（独立，各自的异常不会影响对方）

![img](https://cyc2018.github.io/CS-Notes/pics/96706658-b3f8-4f32-8eb3-dcb7fc8d5381.jpg)

各个线程在创建完成之后就分道扬镳了，一个线程的死亡不会影响到其他线程（Deamon线程会随着被守护线程而消亡）。所以一个线程死亡之前把屁股擦干净。

### 8.2 Interrupt总结

调用线程的**interrupt方法仅能立即打断那些在阻塞状态或者挂起的线程对象（通过抛出异常方式立即处理）**，但是对于正在正常运行的代码块，仅能接受到通知，如果不显示地查看自己的状态（调用线程对象的isInterrupted方法查看是否已经被打断）根本不知道自己已经被打断。这也从另外一个侧面说明一个问题，最好不要使用从外部打断的方式来结束一个正在运行的线程，最好在线程内部自己主动查看标志判断自己是否需要退出。

- 当一个线程被打断之后就不能再次进行线程的调度，即调用sleep、wait、yield等代码块会抛出异常
## 参考资料

- [JAVA 线程状态及转化](https://www.cnblogs.com/happy-coder/p/6587092.html)
- [Java多线程基础知识疑难点](<https://blog.csdn.net/huzhigenlaohu/article/details/51627201#%E6%9C%80%E7%AE%80%E5%8D%95java%E7%A8%8B%E5%BA%8F%E5%8C%85%E5%90%AB%E6%9C%89%E5%93%AA%E4%BA%9B%E7%BA%BF%E7%A8%8B>)
- [Java多线程系列--“JUC锁”07之 LockSupport](https://www.cnblogs.com/skywang12345/p/3505784.html)
- [Java并发编程总结4——ConcurrentHashMap在jdk1.8中的改进](https://www.cnblogs.com/everSeeker/p/5601861.html)
- [说一说Java的Unsafe类](https://www.cnblogs.com/pkufork/p/java_unsafe.html)
- [Java并发之AQS详解](https://www.cnblogs.com/waterystone/p/4920797.html)

