# Mysql

**与红黑二叉树的比较（为什么不选用红黑树的理由）：**

- 更少的查找次数，平衡树以及红黑树的查找时间和树的高度有关为$log_dn$，其中d为子节点的出度，n为元素的个数，所以树的子节点个数越多树的高度越低，查找的次数就越少
- 利用磁盘预读性能，相邻的节点能够被预先载入。
- 为了支持范围查找。

## 1. 存储引擎

**MyISAM更适合读密集的表，而InnoDB更适合写密集的的表**，在数据库做主从分离的时候，经常选择MyIsAm做为主库的存储引擎。

MyIsAM只适合读密集的原因分析：

- 不支持行锁，写入时对表加排它锁，写入性能较差。

Mysql版本5.5 是一个分界线，之前版本的默认存储引擎是MyIsAm，后面版本的默认存储引擎是InnoDB。

### 1.1 MyIsAm

**MyIsAm是Mysql的默认数据库引擎（5.5版本之前）。**

#### 1.1.1 特点

- **不支持行锁(MyISAM只有表锁)**，读取时对需要读到的所有表加锁，写入时则对表加排他锁；

- **不支持事务**

- **不支持外键**

- **不支持崩溃后的安全恢复**

- 在表有读取查询的同时，支持往表中插入新纪录

- 支持BLOB和TEXT的前500个字符索引，**支持全文索引**

- **支持延迟更新索引**，极大地提升了写入性能

- 对于不会进行修改的表，支持 **压缩表** ，极大地减少了磁盘空间的占用

#### 1.1.2 行锁和表锁的区别

- 表级锁：每次操作锁住整张表。开销小，加锁快，不会出现死锁。发生锁冲突的概率最高，并发度最低。
- 行级锁：每次操作锁住一行数据。开销大，加锁慢，会出现死锁；发生锁冲突的概率最低，并发度也最高。

### 1.2 InnoDB

**InnoDB是MySQL的默认数据库引擎（5.5版之后）**,这个存储引擎最出色的的特点是支持**ACID**（事务的四性质）

#### 1.2.1 特点

- 支持行锁，采用MVCC来支持高并发，也有可能死锁
- 支持事务
- 支持外键
- 支持崩溃后的安全恢复
- 不支持全文索引

#### 1.2.2 MVCC(Multi-Version Concurrency Control，多版本并发控制)

其实就是乐观锁的一种实现方式。

![Mysqlä¸­MVCCçä½¿ç¨ååçè¯¦è§£](http://p9.pstatp.com/large/pgc-image/1536289030904c0df31db36)

**基本特征：**

- 每行数据都存在一个版本，每次数据更新时都更新该版本
- 修改时Copy出当前版本随意修改，各个事务之间无干扰
- 保存时比较版本号，如果成功（commit），则覆盖原纪录，失败则放弃copy（rollback）

**实现策略**

在每一行数据中额外保存两个隐藏的列：当前**创建的版本号**和**删除时的版本号**（可能为空，其实还有一列称为回滚指针），即每次添加、修改和删除时都是新增一条记录。

![Mysqlä¸­MVCCçä½¿ç¨ååçè¯¦è§£](http://p98.pstatp.com/large/pgc-image/15362864790262a85896e55)

查询时只有符合下面两个条件的记录才能被查询出来：

- 删除版本号未指定或者大于当前事务版本后，即查询事务开启后确保读取的行未被删除。
- 创建版本号小于或者等于当前事务版本号，也就是记录在当前事务中或者当前事务启动之前其他事务插入（insert）

### 1.3 MyIsAm 和InnoDB的比较

- count运算上的区别，因为MyIsAm缓存有表meta-data（行数等），对于一个结构很好的查询是不需要耗费很多资源的，对于InnoDB来说没有这种缓存。
- 是否支持事务和崩溃后的安全恢复，MyIsAm强调的是性能，每次查询具有原子性，执行速度快，但不支持事务。InnoDB提供事务支持，外部键等高级数据库功能，具有事务、回滚、和崩溃修复能力的安全型表。
- 是否支持外键。MyIsAm不支持，而InnoDB支持。

## 2. 字符集及其校对规则

字符集指的是一种从**二进制编码到某类字符符号的映射**。校对规则则是指某种字符集下的排序规则。Mysql中每一种字符集都会对应一系列的校对规则。MySQL采用的是类似继承的方式指定字符集的默认值，每个数据库以及每张数据表都有自己的默认值，他们逐级继承。

字符集特点：

- 字符编码方式用一个或者多个字节来表示字符集中的一个字符
- 每种字符集都有自己特有的编码方式

常见字符集：

- **ASCII字符集**：基于罗马字母表的一套字符集，**它采用1个字节的低7位表示字符，高位始终为0**。

- **LATIN1字符集**：相对于ASCII字符集做了扩展，**仍然使用一个字节表示字符，但启用了高位**，扩展了字符集的表示范围。
- **GBK字符集**：支持中文，字符有**一字节编码和两字节编码方式。**
- **UTF8字符集**：Unicode字符集的一种，是计算机科学领域里的一项业界标准，支持了所有国家的文字字符，utf8采用**1-4个字节表示字符。**

### 2.1 正确使用字符集

![img](https://images2015.cnblogs.com/blog/1113510/201704/1113510-20170417185653759-1710577496.png)

1.库、表、列字符集的由来

　　①**建库时**，若未明确指定字符集，则采用**character_set_server**指定的字符集。

　　②**建表时**，若未明确指定字符集，则采用**当前库**所采用的字符集。

　　③**新增时**，修改表字段时，若未明确指定字符集，则采用**当前表**所采用的字符集。

2.更新、查询涉及到得字符集变量

　　**更新流程**字符集转换过程：**character_set_client-->character_set_connection-->表字符集**。

　　**查询流程**字符集转换过程：**表字符集-->character_set_result**

3.character_set_database

　　当前默认数据库的字符集，比如执行use xxx后，当前数据库变为xxx，若xxx的字符集为utf8，那么此变量值就变为utf8(供系统设置，无需人工设置)

### 2.2 MySql客户端与字符集

- 对于输入，必须通过**character_set_client、character_set_connection**体现，前者指定了在客户端写入数据时采用的编码（如果这个值和真实的编码值不一样那么必然会发生乱码），如果两者编码不一致会自动转换（转出来还是容易出问题，最好设置为一样的）
- 对于查询，必须通过**character_set_results**来进行体现，默认情况下**character_set_results默认等于character_set_client**

### 2.3 MySql字符编码转换原理

![img](https://images2015.cnblogs.com/blog/1113510/201704/1113510-20170417190125196-906349059.png)

### 2.4 字符集常见处理操作

1. 查看字符集编码设置

```sql
show variables like '%character%';
```

2. 设置字符集编码

```sql
set names 'utf8';

# 等价于同时设置
set character_set_client = utf8;
set character_set_results = utf8;
set character_set_connection = utf8;
```

3. 修改数据库字符集

```sql
alter database database_name character set 'character';
```

4. 修改表的字符集

```sql
alter table table_name character set xxx；

# 只修改表的字符集，影响后续该表新增列的默认定义，已有的不受影响
alter table table_name convert to character set xxx;
```

5. 修改列字符集

```sql
ALTER TABLE table_name MODIFY
	column_name {CHAR | VARCHAR | TEXT} (column_length)
		[CHARACTER SET charset_name]
			[COLLATE collation_name]
			
# eg
alter table table_name modify col_name varchar(col_length) character set xxx;
```

### 2.5 字符集正确实践

　　1.对于insert来说，character_set_client、character_set_connection相同，而且正确反映客户端使用的字符集

　　2.对于select来说，character_set_results正确反映客户端字符集

　　3.数据库字符集取决于我们要存储的字符类型

　　4.**字符集转换最多发生一次**，这就要求**character_set_client、character_set_connection相同**

　　5.所有的**字符集转换都发生在数据库端**

### 2.6 校对规则collatio校对

**校对规则**：是字符集内用于比较和排序的一套规则，有的区分大小写有的不区分

**常见操作：**

```sql
show collation; # 查看数据库支持的所有校对规则
show variables like 'collation_%'; 查看当前字符集和校对规则设置
```

**校对规则特征**

①两个不同的字符集不能有相同的校对规则；

②每个字符集有一个默认校对规则；

③存在校对规则命名约定：以其相关的字符集名开始，中间包括一个语言名，并且以_ci（大小写不敏感）、_cs（大小写敏感）或_bin（二元）结束

## 3.  索引相关

Mysql的索引结构主要有**BTree索引**和**哈希索引**，哈希索引适合于单记录查询的时候，其余大部分场景建议选择BTree索引。Mysql中主要使用的BTree索引主要是B+Tree，但对于这主要的两种存储引擎的实现方式是不同的。

- MyIsAm： B+Tree叶节点的data域存放的是数据记录的地址，查询时首先读取地址然后在取地址对应的数据记录，这被称为“**非聚簇索引**”
- InnoDB：其数据文件本身就是索引文件，表数据本身就是主索引，这被称为“**聚簇索引**”。其余的索引都是辅助索引，**辅助索引的data域存储对应主键的值而不是地址**。**根据主索引搜索：直接找到key所在的节点即可取出数据；根据辅助索引搜索时：则需要先取出主键的值，再走一遍主索引（回表？）。因此在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，会造成主键的频繁分裂**

**索引存在的意义？**

- O（n）时间复杂度的顺序查找太慢了
- 二分查找、二叉排序树只适用于特定的数据（有序）
- 只能针对一个字段，数据之外维护的满足特定查找的数据结构

**索引优点**

- 通过创建唯一性索引，可以保证每一行数据的唯一性
- 加快检索的速度
- 加速表和表之间的连接
- 在使用分组和排序字句进行检索时，同样可以减少查询中分组和排序时间
- 查询过程中，使用优化隐藏器，提高系统性能

**索引缺点**

- 创建索引和维护索引需要耗费时间，并且时间随着数据量的增加而增加
- 索引需要占用物理空间，如果需要建立聚簇索引话那么需要的空间更大
- 当对表中数据进行增加、删除、修改的时候，索引也需要动态维护，降低了数据的维护速度

### 3.1 B树

B-树、B+树，B*树具体见数据结构部分总结。

### 3.2 MyIsAm索引

主索引如下所示：

![img](https://upload-images.jianshu.io/upload_images/5687393-942f8ec950b81e79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

辅助索引如下图所示，和主索引没有差别，只是允许key值重复

![img](https://upload-images.jianshu.io/upload_images/5687393-99c73161973f6c2f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

### 3.2 InnoDB索引

主索引：索引本身也是数据，属于聚簇索引，必须根据主键来进行确定

![img](https://upload-images.jianshu.io/upload_images/5687393-f7686f5fd8dc3c43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

辅助索引：叶子节点存储不是地址而是主键值，需要在主索引中再进行查找

![img](https://upload-images.jianshu.io/upload_images/5687393-a816c1e214faecb2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

### 3.3 索引的使用

#### 3.3.1 创建索引

```sql
//第一种方式：
//在执行CREATE TABLE 时创建索引：（硬设一个id索引）
CREATE TABLE `black_list` (
	`id` BIGINT(20) NOT NULL AUTO_INCREMENT,
	`black_user_id` BIGINT(20) NULL DEFAULT NULL,
	`user_id` BIGINT(20) NULL DEFAULT NULL,
	PRIMARY KEY (`id`)
    INDEX indexName (black_user_id(length))
)
COLLATE='utf8_general_ci'
ENGINE=InnoDB
;

//第二种方式使用Alter语句
ALTER TABLE table_name ADD INDEX index_name (column_list)//添加普通索引，索引值可出现多次。 
ALTER TABLE table_name ADD UNIQUE (column_list)//这条语句创建的索引的值必须是唯一的(除了NULL外，NULL可能会出现多次)。 
ALTER TABLE table_name ADD PRIMARY KEY (column_list)//该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。
ALTER TABLE table_name ADD FULLTEXT index_name(olumu_name);该语句指定了索引为FULLTEXT，用于全文索引。
//针对上述数据库，增加商品分类的索引
ALTER table commodity_list ADD INDEX classify_index  (Classify_Description)

//第三种方式使用 Create [unique] Index 方式
CREATE INDEX index_name ON table_name (column_list)
CREATE UNIQUE INDEX index_name ON table_name (column_list)
//针对上述数据库：
CREATE INDEX classify_index  ON commodity_list (Classify_Description)
```

#### 3.3.2 删除索引

```
DROP INDEX [indexName] ON [table_name];
alter table [table_name] drop index [index_name] ;
alter table [table_name] drop primary key ;
//针对上述数据库
drop index classify_index on commodity_list ;
```

#### 3.3.3 查看索引

```sql
SHOW INDEX FROM [table_name];
show keys from [table_name];
```

### 3.4 索引的分类

- 基本索引
- 唯一索引，必须唯一，允许为空
- 主键索引，特殊的唯一索引，不允许为空
- 全文索引，对大数据文本进行索引，在建立的索引中搜索要查找的单词，必须是MyIsAm存储引擎

```sql
//针对content做了全文索引：
CREATE TABLE `table` (
`id` int(11) NOT NULL AUTO_INCREMENT ,
`title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,
`content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,
PRIMARY KEY (`id`),
FULLTEXT (content)
);

//使用
SELECT * FROM article WHERE MATCH( content) AGAINST('想查询的字符串')
```

### 3.5 单列索引和多列索引

- 单列索引，没有什么说的

- 多列索引，多个单列索引和多列索引的查询效果不同，因为执行时只选择了限制最为严格的索引。

  **适用场景**：全字段匹配、匹配部分最左前缀、匹配第一列、匹配第一列范围查询、精确匹配某一列和范围匹配另外一列。

  **组合索引原则：**最左前缀，就是最左优先。

创建多列索引中也涉及到一种特殊的索引---->**覆盖索引**（查询出的列和索引是对应的，不需要进行回表操作）

#### 3.5.1 索引最左匹配原则

联合索引：其实就是多列索引

**索引只能用于查找key是否存在（相等）**，遇到索引失效的情况就不能够再继续使用索引了（例如：> ,< , between）退化为线性查找

列的排列顺序决定了可命中索引的列数。

最简单的理解为：从左开始匹配时一直使用索引直到遇到不能使用情况后再退化为线性扫描。

### 3.6 聚簇索引和非聚簇索引

![èéç´¢å¼åéèéç´¢å¼çåºå"æåªäº](https://imgsa.baidu.com/exp/w=500/sign=d7b0c3d81c950a7b75354ec43ad3625c/6a63f6246b600c331cfc46261b4c510fd8f9a153.jpg)

#### 3.6.1 聚簇索引

该索引中键值的逻辑顺序决定了表中相应行的物理顺序。

**注意：**使用聚簇索引时使用的列越少越好

**使用场景**

一）包含**大量非重复值**的列。

二）使用下列运算符返回一个**范围值的查询**：BETWEEN、>、>=、< 和 <=。

三）被**连续访问的列**。

四）返回**大型结果集的查询**。

五）经常被使用**联接或 GROUP BY 子句的查询访问的列**；一般来说，这些是**外键列**。对 ORDER BY 或 GROUP BY 子句中指定的列进行索引，可以使 SQL Server 不必对数据进行排序，因为这些行已经排序。这样可以提高查询性能。

六）**OLTP 类型**的应用程序，这些程序要求进行非常快速的单行查找（一般通过主键）。

#### 3.6.2 非聚簇索引（需要回表操作）

数据存储在一个地方，索引存储在另一个地方，索引带有指针指向数据的存储位置。

#### 3.6.3 关于非聚簇和聚簇索引的几个问题

1. #### **聚集索引的约束是唯一性，是否要求字段也是唯一的呢？**

   聚簇索引可以创建在任何一列上，但是一般不这么做

2. #### **主键就是聚集索引？？？**

   不一定，一个表中只能有一个聚簇索引，所以可以把其留给其他更有需要的地方。

3. #### **是不是聚集索引就一定要比非聚集索引性能优呢？？？**

   否，比如联合索引能够直接覆盖输出时。

4. #### **在数据库中通过什么描述聚集索引与非聚集索引的？**

   聚集索引的叶节点就是最终的数据节点，而非聚集索引的叶节仍然是索引节点，但它有一个指向最终数据的指针。

5. #### **在主键是创建聚集索引的表在数据插入上为什么比主键上创建非聚集索引表速度要慢？**

   由于有主键唯一性的约束，所以需要保证插入的数据没有重复。聚簇索引需要读取所有的数据判断是否重复，而非聚簇索引直接读取叶子上的索引页就能知道是否重复。**节点中是否具有数据，数据一般比索引大，遍历数据比遍历索引费时间**

### 3.7 索引设计优化

#### 3.7.1 建立索引的原则

- 最左前缀匹配原则
- =和in可以乱序
- 尽量选择区分度高的列作为索引，区分度的计算公式是count(distinct col)/count(*)
- 索引列不参与计算，保持列干净
- 尽量地拓展索引，不要新建索引
- 定义外键的数据列一定要建立索引
- 对于查询中很少涉及的列，重复值比较多的列不要建立索引
- 对于定义为text、image、bit的数据类型列不要建立索引
- 对于经常存取的列避免建立索引

#### 3.7.2 索引使用注意点（基本就是放弃使用索引的情况）

- 索引应该建立在用于join、where和order by的字段上
- 索引不是越多越好
- 尽可能避免对聚簇索引列的更新
- 尽量避免向客户端返回大数据量，过大需求可能不合理
- mysql查询中只使用一个索引，所以在where 中使用了索引后，order by就不会使用索引

**放弃使用索引进行全表扫描的情况：**

- 尽量避免在where字句中对null值判断，否则导致引擎放弃索引而进行全表扫描，于是字段一般要有不空限制，null也不一定代表不需要使用空间
- 尽量避免在where字句中使用!= 或者 <> 操作符，否则引擎将放弃使用索引进行全表扫描
- 避免在where字句中使用or连接，如果一个字段有索引另外一个没有，导致放弃索引进行全表扫描
- in和not in也要慎用，否则会导致全表扫描，能用between或者exists就不适用in
- 以通配符开始的模糊查询也不用索引，导致全表扫描
- where子句中使用参数导致全表扫描
- 避免在where字句中对字段进行函数操作，导致全表扫描
- 需要在where子句的“=”左边进行函数、算法运算或其他表达式运算，否则系统无法正确使用索引
- 复合索引尽可能让字段顺序和索引顺序相一致

### 3. 8 索引基础知识

![img](https://user-gold-cdn.xitu.io/2018/7/23/164c6d7a53a7920b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

![img](https://user-gold-cdn.xitu.io/2018/7/23/164c6d7a53b78847?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 各个数据页可以组成一个双向链表
- 每个数据页中的记录又可以组成一个单向链表
  - 基于主键的查找：每个数据页都会为存储在它里边儿的记录生成一个**页目录**，在通过**主键**查找某条记录的时候可以在页目录中使用**二分法快速定位**到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录
  - 基于其他列的查找：以**其他列**(非主键)作为搜索条件：只能从最小记录开始**依次遍历单链表中的每条记录**。

### 3.9 哈希索引

对照HashMap来进行理解就对了。

![img](https://user-gold-cdn.xitu.io/2018/7/23/164c6d7a55fd52b3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**局限：**

- 哈希索引也没有办法利用索引完成排序（**不支持排序**）
- 不支持**最左匹配原则**
- 有大量重复键值的情况下，哈希索引效率也是极低的（**哈希碰撞问题**）
- **不支持范围查询**

#### 3.9.1 InnoDB支持哈希索引？

主流的还是采用**B+树搜索索引**，对于哈希索引，**InnoDB**是自适应哈希索引（创建有存储引擎自动优化创建，开发人员干预不了）

## 4.  查询缓存的使用

my.cnf加入以下配置，重启Mysql开启查询缓存

```properties
query_cache_type=1
query_cache_size=600000
```

Mysql执行以下命令也可以开启查询缓存

```sql
set global  query_cache_type=1;
set global  query_cache_size=600000;
```

如上，**开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果**。这里的查询条件**包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息**。因此任何两个查询在任何字符上的不同都会导致缓存不命中。

此外，如果查询中**包含任何用户自定义函数、存储函数、用户变量、临时表、Mysql库中的系统表，其查询结果也不会被缓存**。

缓存建立之后，Mysql的查询缓存系统会跟踪查询中涉及的每张表，如果这些**表（数据或结构）发生变化**，那么和这张表相关的所有缓存数据都将**失效**。

**缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。** 因此，开启缓存查询要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十MB比较合适。此外，**还可以通过sql_cache和sql_no_cache来控制某个查询语句是否需要缓存：**

```sql
select sql_no_cache count(*) from usr;
```

## 5. 事务机制

- **关系性数据库需要遵循ACID规则，具体内容如下：**

[![事务的特性](https://camo.githubusercontent.com/d9451f7f07cc2be36bcbbebbeab6d5d734c42c2f/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f352f32302f313633376230386239383631393435353f773d33313226683d33303526663d706e6726733d3232343330)](https://camo.githubusercontent.com/d9451f7f07cc2be36bcbbebbeab6d5d734c42c2f/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f352f32302f313633376230386239383631393435353f773d33313226683d33303526663d706e6726733d3232343330)

1. **原子性：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性：** 执行事务前后，数据库从一个一致性状态转换到另一个一致性状态。
3. **隔离性：** 并发访问数据库时，一个用户的事物不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库 发生故障也不应该对其有任何影响。

**为了达到上述事务特性，数据库定义了几种不同的事务隔离级别：**

- **READ_UNCOMMITTED（未提交读）:** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**

- **READ_COMMITTED（提交读）:** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**

- **REPEATABLE_READ（可重复读）:** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**

- **SERIALIZABLE（串行）:** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

  这里需要注意的是：**Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.**

  事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVCC（多版本并发控制），通过行的创建时间和行的过期时间来支持并发一致性读和回滚等特性。

  详细内容可以参考： [可能是最漂亮的Spring事务管理详解](https://blog.csdn.net/qq_34337272/article/details/80394121)

## 6. 锁机制与InnoDB锁算法

**MyISAM和InnoDB存储引擎使用的锁：**

- MyISAM采用表级锁(table-level locking)。
- InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁

**表级锁和行级锁对比：**

- **表级锁：** Mysql中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。
- **行级锁：** Mysql中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

详细内容可以参考： [Mysql锁机制简单了解一下](https://blog.csdn.net/qq_34337272/article/details/80611486)

**InnoDB存储引擎的锁的算法有三种：**

- Record lock：单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap 锁定一个范围，包含记录本身

**相关知识点：**

1. innodb对于行的查询使用next-key lock
2. Next-locking keying为了解决Phantom Problem幻读问题
3. 当查询的索引含有唯一属性时，将next-key lock降级为record key
4. Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
5. 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

![InnoDBçéæºå¶å¼å®¹æåµ](https://user-gold-cdn.xitu.io/2018/6/7/163da3105cb54186?w=672&h=159&f=png&s=8700)

### 6.1 锁

![img](https://user-gold-cdn.xitu.io/2018/7/23/164c6d7ae44d8ac6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### 6.1.1 为什么需要学习数据库锁知识

数据库隐式加锁：

- 对于UPdate、DELETE、INSERT自动加写锁
- select前自动加读锁

学习锁知识的目的：

- 特定场所手动加锁
- 更好把控自己写的代码

#### 6.1.2 表锁

**读锁和写锁是互斥的，读写操作是串行**。

- 如果某个进程想要获取读锁，**同时**另外一个进程想要获取写锁。在mysql里边，**写锁是优先于读锁的**！
- 写锁和读锁优先级的问题是可以通过参数调节的：`max_write_lock_count`和`low-priority-updates`

**MyISAM可以**支持查询和插入操作的**并发**进行。可以通过系统变量`concurrent_insert`来指定哪种模式，在**MyISAM**中它默认是：如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从**表尾**插入记录。

但是**InnoDB存储引擎是不支持查询和插入并发的**！

#### 6.1.3 行锁

InnoDB实现了以下两种类型的行锁：

- 共享锁（S锁）
- 排它锁（X锁）

**为了允许行锁和表锁共存，实现多粒度锁机制**，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。
- 意向锁也是数据库隐式帮我们做了，**不需要程序员操心**！

##### 6.1.3.1 MVCC和事务的隔离级别

**MVCC就是行级锁的一种变种（升级版）**

事务的隔离级别就是通过锁机制来实现。

MVCC的读写不阻塞，通过一定的机制生成一个数据请求时间点的一致性数据快照，利用这个快照提供一定级别一致性读取，从用户角度看就是数据提供提供同一数据的多个版本。

**快照级别：**

- **语句级别**：针对**Read Committed**隔离级别

  只查找版本不晚于当前事务版本的数据行，行的版本号要么未定义要么大于当前事务版本号，可以确保事务开始之前未删除

- **事务级别**：针对**Repeatable read**隔离级别

**事务隔离级别**

- read uncommitted，会出现脏读，不可重复读，幻读
- read committed，会出现不可重复读，幻读
- repeatable read，会出现幻读（mysql中配合gap锁不会出现幻读）
- Serializable，串行，避免以上情况

#### 6.1.4 乐观锁和悲观锁

悲观锁就是认为冲突会发生，提前就加上了排他锁（一般为行锁）。

乐观锁就是认为冲突不会发生，或者等到冲突发生时再去解决冲突。乐观锁一般使用版本号来进行实现，为每次操作加入版本号，修改后准备提交前如果当前的版本号和之前查到的版本不一致，说明发生了冲突，需要解决这个冲突（回滚）。

![img](https://user-gold-cdn.xitu.io/2018/7/23/164c6d7bda2aa2b3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### 6.1.5 间隙锁GAP

当我们**用范围条件检索数据**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给**符合范围条件的已有数据记录的索引项加锁**；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”。InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。

**目的**

- 为了防止幻读
- 满足恢复和复制的需要
  - MySQL的恢复机制要求：**在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读**

#### 6.1.6 如何尽可能避免死锁

- 以固定的顺序访问表和行
- 大事务拆小
- 降低隔离级别
- 为表添加合理的索引，**尽可能少访问数据就能减少加锁操作，加锁操作少也就说就更不容易发生死锁**
- 同一个事务尽可能做到一次锁定所需要的所有资源

#### 6.1.7 页级锁

 MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。页级进行了折衷，一次锁定相邻的一组记录。BDB支持页级锁。开销和加锁时间界于表锁和行锁之间，会出现死锁。锁定粒度界于表锁和行锁之间，并发度一般。

## 7. 大表优化

1. **保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。**

   水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

   [![数据库水平拆分](https://camo.githubusercontent.com/55e640f3c724c56d464e5795ffb557a7a50b8d84/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f362f31362f313634303834623765396534323365333f773d36393026683d32373126663d6a70656726733d3233313139)](https://camo.githubusercontent.com/55e640f3c724c56d464e5795ffb557a7a50b8d84/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f362f31362f313634303834623765396534323365333f773d36393026683d32373126663d6a70656726733d3233313139)

   水平拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 **水平拆分最好分库** 。

   水平拆分能够 **支持非常大的数据量存储，应用端改造也少**，但 **分片事务难以解决** ，跨界点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 **尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度** ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

   **下面补充一下数据库分片的两种常见方案：**

   - **客户端代理：** **分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。
   - **中间件代理：** **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。

详细内容可以参考： [MySQL大表优化方案](https://segmentfault.com/a/1190000006158186)

### 7.1 表单优化

#### 7.1.1 字段

- 尽量使用`TINYINT`、`SMALLINT`、`MEDIUM_INT`作为整数类型而非`INT`，如果非负则加上`UNSIGNED``
- ``VARCHAR`的长度只分配真正需要的空间
- 使用枚举或整数代替字符串类型
- 尽量使用`TIMESTAMP`而非`DATETIME`，
- 单表不要有太多字段，建议在 20 以内
- 避免使用 NULL 字段，很难查询优化且占用额外索引空间
- 用整型来存 IP

#### 7.1.2 索引

- 索引并不是越多越好，要根据查询有针对性的创建，考虑在`WHERE`和`ORDER BY`命令上涉及的列建立索引，可根据`EXPLAIN`来查看是否用了索引还是全表扫描

- 应尽量避免在`WHERE`子句中对字段进行`NULL`值判断，否则将导致引擎放弃使用索引而进行全表扫描

- 值分布很稀少的字段不适合建索引，例如 "性别" 这种只有两三个值的字段

- 字符字段只建前缀索引

- 字符字段最好不要做主键

- 不用外键，由程序保证约束

- 尽量不用`UNIQUE`，由程序保证约束

- 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引

#### 7.1.3 查询Sql

- 可通过开启慢查询日志来找出较慢的 SQL

- 不做列运算：`SELECT id WHERE age + 1 = 10`，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边

- sql 语句尽可能简单：一条 sql 只能在一个 cpu 运算；大语句拆小语句，减少锁时间；一条大 sql 可以堵死整个库

- 不用`SELECT *`

- `OR`改写成`IN`：`OR`的效率是 n 级别，`IN`的效率是 log(n) 级别，in 的个数建议控制在 200 以内

- 不用函数和触发器，在应用程序实现

- 避免`%xxx`式查询

- 少用`JOIN`

- 使用同类型进行比较，比如用`'123'`和`'123'`比，`123`和`123`比

- 尽量避免在`WHERE`子句中使用!= 或 <> 操作符，否则将引擎放弃使用索引而进行全表扫描

- 对于连续数值，使用`BETWEEN`不用`IN`：`SELECT id FROM t WHERE num BETWEEN 1 AND 5`

- 列表数据不要拿全表，要使用`LIMIT`来分页，每页数量也不要太大

### 7.2 系统参数调优

#### 7.2.1 工具

- [sysbench](https://github.com/akopytov/sysbench)：一个模块化，跨平台以及多线程的性能测试工具

- [iibench-mysql](https://github.com/tmcallaghan/iibench-mysql)：基于 Java 的 MySQL/Percona/MariaDB 索引进行插入性能测试工具

- [tpcc-mysql](https://github.com/Percona-Lab/tpcc-mysql)：Percona 开发的 TPC-C 测试工具

#### 7.2.2 重要的参数

- back_log：back_log 值指出在 MySQL 暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果 MySql 的连接数据达到 max_connections 时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即 back_log，如果等待连接的数量超过 back_log，将不被授予连接资源。可以从默认的 50 升至 500

- wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的 8 小时减到半小时

- max_user_connection: 最大连接数，默认为 0 无上限，最好设一个合理上限

- thread_concurrency：并发线程数，设为 CPU 核数的两倍

- skip_name_resolve：禁止对外部连接进行 DNS 解析，消除 DNS 解析时间，但需要所有远程主机用 IP 访问

- key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对 MyISAM 表性能影响最大。对于内存 4G 左右，可设为 256M 或 384M，通过查询`show status like 'key_read%'`，保证`key_reads / key_read_requests`在 0.1% 以下最好

- innodb_buffer_pool_size：缓存数据块和索引块，对 InnoDB 表性能影响最大。通过查询`show status like 'Innodb_buffer_pool_read%'`，保证` (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests`越高越好

- innodb_additional_mem_pool_size：InnoDB 存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL 会记录 Warning 信息到数据库的错误日志中，这时就需要该调整这个参数大小

- innodb_log_buffer_size：InnoDB 存储引擎的事务日志所使用的缓冲区，一般来说不建议超过 32MB

- query_cache_size：缓存 MySQL 中的 ResultSet，也就是一条 SQL 语句执行的结果集，所以仅仅只能针对 select 语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的 select 语句在 Query Cache 中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用 Query Cache 可能会得不偿失。根据命中率`(Qcache_hits/(Qcache_hits+Qcache_inserts)*100))`进行调整，一般不建议太大，256MB 可能已经差不多了，大型的配置型静态数据可适当调大.
  可以通过命令`show status like 'Qcache_%'`查看目前系统 Query catch 使用大小

- read_buffer_size：MySql 读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql 会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能

- sort_buffer_size：MySql 执行排序使用的缓冲大小。如果想要增加`ORDER BY`的速度，首先看是否可以让 MySQL 使用索引而不是额外的排序阶段。如果不能，可以尝试增加 sort_buffer_size 变量的大小

- read_rnd_buffer_size：MySql 的随机读缓冲区大小。当按任意顺序读取行时 (例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql 会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但 MySql 会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。

- record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值

- thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的

- table_cache：类似于 thread_cache_size，但用来缓存表文件，对 InnoDB 效果不大，主要用于 MyISAM

#### 7.2.3 升级硬件

Scale up，这个不多说了，根据 MySQL 是 CPU 密集型还是 I/O 密集型，通过提升 CPU 和内存、使用 SSD，都能显著提升 MySQL 性能

### 7.3 读写分离

也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离

**分离的原因**

- 主从服务器负责各自的读和写，极大程度缓解了锁的争用；
- 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
- 增加冗余，提高可用性。

读写分离常采用代理方式来实现，代理服务器接受应用层传来的读写请求，然后决定转发到哪个服务器。

![img](https://cyc2018.github.io/CS-Notes/pics/master-slave-proxy.png)

### 7.4 缓存

缓存可以发生在这些层次：

- MySQL 内部：在系统调优参数介绍了相关设置
- 数据访问层：比如 MyBatis 针对 SQL 语句做缓存，而 Hibernate 可以精确到单个记录，这里缓存的对象主要是持久化对象`Persistence Object`
- 应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象`Data Transfer Object`
- Web 层：针对 web 页面做缓存
- 浏览器客户端：用户端的缓存

可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式：

- 直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如 Spring Cache 的工作方式。这种实现非常简单，同步好，但效率一般。
- 回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。

### 7.5 表分区

MySQL 在 5.1 版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码

对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对 SQL 层来说是一个完全封装底层的黑盒子。MySQL 实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引



![img](https://segmentfault.com/img/remote/1460000006767126)



用户的 SQL 语句是需要针对分区表做优化，SQL 条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过`EXPLAIN PARTITIONS`来查看某条 SQL 语句会落在那些分区上，从而进行 SQL 优化，如下图 5 条记录落在两个分区上：

```
mysql> explain partitions select count(1) from user_partition where id in (1,2,3,4,5);
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
| id | select_type | table          | partitions | type  | possible_keys | key     | key_len | ref  | rows | Extra                    |
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
|  1 | SIMPLE      | user_partition | p1,p4      | range | PRIMARY       | PRIMARY | 8       | NULL |    5 | Using where; Using index |
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
1 row in set (0.00 sec)
```

分区的好处是：

- 可以让单表存储更多的数据
- 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作
- 部分查询能够从查询条件确定只落在少数分区上，速度会很快
- 分区表的数据还可以分布在不同的物理设备上，从而高效利用多个硬件设备
- 可以使用分区表赖避免某些特殊瓶颈，例如 InnoDB 单个索引的互斥访问、ext3 文件系统的 inode 锁竞争
- 可以备份和恢复单个分区

分区的限制和缺点：

- 一个表最多只能有 1024 个分区
- 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来
- 分区表无法使用外键约束
- NULL 值会使分区过滤无效
- 所有分区必须使用相同的存储引擎

分区的类型：

- RANGE 分区：基于属于一个给定连续区间的列值，把多行分配给分区
- LIST 分区：类似于按 RANGE 分区，区别在于 LIST 分区是基于列值匹配一个离散值集合中的某个值来进行选择
- HASH 分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含 MySQL 中有效的、产生非负整数值的任何表达式
- KEY 分区：类似于按 HASH 分区，区别在于 KEY 分区只支持计算一列或多列，且 MySQL 服务器提供其自身的哈希函数。必须有一列或多列包含整数值

分区适合的场景有：

- 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示：

```
CREATE TABLE members (
    firstname VARCHAR(25) NOT NULL,
    lastname VARCHAR(25) NOT NULL,
    username VARCHAR(16) NOT NULL,
    email VARCHAR(35),
    joined DATE NOT NULL
)
PARTITION BY RANGE( YEAR(joined) ) (
    PARTITION p0 VALUES LESS THAN (1960),
    PARTITION p1 VALUES LESS THAN (1970),
    PARTITION p2 VALUES LESS THAN (1980),
    PARTITION p3 VALUES LESS THAN (1990),
    PARTITION p4 VALUES LESS THAN MAXVALUE
);
```

查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。

- 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存

另外 MySQL 有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代

### 7.6 垂直拆分

垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联

比如原始的用户表是：



![img](https://segmentfault.com/img/remote/1460000006158196)



垂直拆分后是：



![img](https://segmentfault.com/img/remote/1460000006158199)



垂直拆分的优点是：

- 可以使得行数据变小，一个数据块 (Block) 就能存放更多的数据，在查询时就会减少 I/O 次数(每次查询时读取的 Block 就少)
- 可以达到最大化利用 Cache 的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起
- 数据维护简单

缺点是：

- 主键出现冗余，需要管理冗余列
- 会引起表连接 JOIN 操作（增加 CPU 开销）可以通过在业务服务器上进行 join 来减少数据库压力
- 依然存在单表数据量过大的问题（需要水平拆分）
- 事务处理复杂

### 7.7 水平拆分

#### 7.7.1 概述

水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的 MySQL 表或库，达到分布式的效果，能够支持非常大的数据量。前面的表分区本质上也是一种特殊的库内分表

库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻 MySQL 服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的 IO、CPU、网络，这个就要通过分库来解决

前面垂直拆分的用户表如果进行水平拆分，结果是：



![img](https://segmentfault.com/img/remote/1460000006158207)



实际情况中往往会是垂直拆分和水平拆分的结合，即将`Users_A_M`和`Users_N_Z`再拆成`Users`和`UserExtras`，这样一共四张表

水平拆分的优点是:

- 不存在单库大数据和高并发的性能瓶颈
- 应用端改造较少
- 提高了系统的稳定性和负载能力

**缺点是**：

- 分片事务一致性难以解决
- 跨节点 Join 性能差，逻辑复杂
- 数据多次扩展难度跟维护量极大
- 需要分布式ID生成器，保证ID的唯一性

**分片策略:**

- 哈希取模
- 范围，例如时间范围或者id范围
- 映射表，使用单独的数据库来存储映射关系

#### 7.7.2 分片原则

- 能不分就不分，参考单表优化
- 分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询 SQL 跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量
- 分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性 Hash 分片，这几种分片都有利于扩容
- 尽量不要在一个事务中的 SQL 跨越多个分片，分布式事务一直是个不好处理的问题
- 查询条件尽量优化，尽量避免 Select * 的方式，大量数据结果集下，会消耗大量带宽和 CPU 资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。
- 通过数据冗余和表分区赖降低跨库 Join 的可能

这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。

总体上来说，分片的选择是取决于最频繁的查询 SQL 的条件，因为不带任何 Where 语句的查询 SQL，会遍历所有的分片，性能相对最差，因此这种 SQL 越多，对系统的影响越大，所以我们要尽量避免这种 SQL 的产生。

#### 7.7.3 解决方案

由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。

##### 7.7.3.1 客户端架构

通过修改数据访问层，如 JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以 Jar 包的方式呈现

这是一个客户端架构的例子：



![img](https://segmentfault.com/img/remote/1460000006158210)



可以看到分片的实现是和应用服务器在一起的，通过修改 Spring JDBC 层来实现

客户端架构的优点是：

- 应用直连数据库，降低外围系统依赖所带来的宕机风险
- 集成成本低，无需额外运维的组件

缺点是：

- 限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心
- 将分片逻辑的压力放在应用服务器上，造成额外风险

##### 7.7.3.2 代理架构

通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件

这是一个代理架构的例子：



![img](https://segmentfault.com/img/remote/1460000006767127)



代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要 Zookeeper 之类的服务组件来管理

代理架构的优点是：

- 能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强
- 对于应用服务器透明且没有增加任何额外负载

缺点是：

- 需部署和运维独立的代理中间件，成本高
- 应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险

##### 7.7.3.3 各方案比较

|                                                              | 出品方     | 架构模型   | 支持数据库 | 分库 | 分表 | 读写分离 | 外部依赖 | 是否开源   | 实现语言 | 支持语言 | 最后更新  | GITHUB 星数 |
| ------------------------------------------------------------ | ---------- | ---------- | ---------- | ---- | ---- | -------- | -------- | ---------- | -------- | -------- | --------- | ----------- |
| [MySQL Fabric](https://www.mysql.com/products/enterprise/fabric.html) | MySQL 官方 | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | python   | 无限制   | 4 个月前  | 35          |
| [Cobar](https://github.com/alibaba/cobar)                    | 阿里巴巴   | 代理架构   | MySQL      | 有   | 无   | 无       | 无       | 是         | Java     | 无限制   | 两年前    | 1287        |
| [Cobar Client](https://github.com/alibaba/cobarclient)       | 阿里巴巴   | 客户端架构 | MySQL      | 有   | 无   | 无       | 无       | 是         | Java     | Java     | 三年前    | 344         |
| [TDDL](https://github.com/alibaba/tb_tddl)                   | 淘宝       | 客户端架构 | 无限制     | 有   | 有   | 有       | Diamond  | 只开源部分 | Java     | Java     | 未知      | 519         |
| [Atlas](https://github.com/Qihoo360/Atlas)                   | 奇虎 360   | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | C        | 无限制   | 10 个月前 | 1941        |
| [Heisenberg](https://github.com/brucexx/heisenberg)          | 百度熊照   | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | Java     | 无限制   | 2 个月前  | 197         |
| [TribeDB](https://github.com/jojoin/TribeDB)                 | 个人       | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | NodeJS   | 无限制   | 3 个月前  | 126         |
| [ShardingJDBC](https://github.com/dangdangdotcom/sharding-jdbc) | 当当       | 客户端架构 | MySQL      | 有   | 有   | 有       | 无       | 是         | Java     | Java     | 当天      | 1144        |
| [Shark](https://github.com/gaoxianglong/shark)               | 个人       | 客户端架构 | MySQL      | 有   | 有   | 无       | 无       | 是         | Java     | Java     | 两天前    | 84          |
| [KingShard](https://github.com/flike/kingshard)              | 个人       | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | Golang   | 无限制   | 两天前    | 1836        |
| [OneProxy](http://www.onexsoft.com/?page_id=3383)            | 平民软件   | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 否         | 未知     | 无限制   | 未知      | 未知        |
| [MyCat](http://mycat.io/)                                    | 社区       | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | Java     | 无限制   | 两天前    | 1270        |
| [Vitess](https://github.com/youtube/vitess)                  | Youtube    | 代理架构   | MySQL      | 有   | 有   | 有       | 无       | 是         | Golang   | 无限制   | 当天      | 3636        |
| [Mixer](https://github.com/siddontang/mixer)                 | 个人       | 代理架构   | MySQL      | 有   | 有   | 无       | 无       | 是         | Golang   | 无限制   | 9 个月前  | 472         |
| [JetPants](https://github.com/tumblr/jetpants)               | Tumblr     | 客户端架构 | MySQL      | 有   | 有   | 无       | 无       | 是         | Ruby     | Ruby     | 10 个月前 | 957         |
| [HibernateShard](https://github.com/hibernate/hibernate-shards) | Hibernate  | 客户端架构 | 无限制     | 有   | 有   | 无       | 无       | 是         | Java     | Java     | 4 年前    | 57          |
| [MybatisShard](https://github.com/makersoft/mybatis-shards)  | MakerSoft  | 客户端架构 | 无限制     | 有   | 有   | 无       | 无       | 是         | Java     | Java     | 11 个月前 | 119         |
| [Gizzard](https://github.com/twitter/gizzard)                | Twitter    | 代理架构   | 无限制     | 有   | 有   | 无       | 无       | 是         | Java     | 无限制   | 3 年前    | 2087        |

如此多的方案，如何进行选择？可以按以下思路来考虑：

1. 确定是使用代理架构还是客户端架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构
2. 具体功能是否满足，比如需要跨节点`ORDER BY`，那么支持该功能的优先考虑
3. 不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持
4. 最好按大公司 -> 社区 -> 小公司 -> 个人这样的出品方顺序来选择
5. 选择口碑较好的，比如 github 星数、使用者数量质量和使用者反馈
6. 开源的优先，往往项目有特殊需求可能需要改动源代码

按照上述思路，推荐以下选择：

- 客户端架构：ShardingJDBC
- 代理架构：MyCat 或者 Atlas

### 7.8 兼容 MySQL 且可水平扩展的数据库

目前也有一些开源数据库兼容 MySQL 协议，如：

- [TiDB](https://github.com/pingcap/tidb)
- [Cubrid](http://www.cubrid.org/)

但其工业品质和 MySQL 尚有差距，且需要较大的运维投入，如果想将原始的 MySQL 迁移到可水平扩展的新数据库中，可以考虑一些云数据库：

- [阿里云 PetaData](https://cn.aliyun.com/product/petadata/?spm=5176.7960203.237031.38.cAzx5r)
- [阿里云 OceanBase](https://cn.aliyun.com/product/oceanbase?spm=5176.7960203.237031.40.cAzx5r)
- [腾讯云 DCDB](https://www.qcloud.com/product/dcdb_for_tdsql.html)

### 7.9 NoSQL

在 MySQL 上做 Sharding 是一种戴着镣铐的跳舞，事实上很多大表本身对 MySQL 这种 RDBMS 的需求并不大，并不要求 ACID，可以考虑将这些表迁移到 NoSQL，彻底解决水平扩展问题，例如：

- 日志类、监控类、统计类数据
- 非结构化或弱结构化数据
- 对事务要求不强，且无太多关联操作的数据

## 8. 索引总结

![ãæç"´å¯¼å¾-ç´¢å¼ç¯ã](https://camo.githubusercontent.com/0e14b18be2cf0335c3c7d5214aac215f83bf830d/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31302d322f37303937333438372e6a7067)

## 9. 主从复制

### 9.1 主从复制

主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。

- **binlog 线程** ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。
- **I/O 线程** ：负责从主服务器上读取二进制日志，并写入从服务器的重放日志（Replay log）中。
- **SQL 线程** ：负责读取重放日志并重放其中的 SQL 语句。